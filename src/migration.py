import asyncio
import logging
from pathlib import Path
from typing import List
import xml.etree.ElementTree as ET

from sqlalchemy import select, inspect, text
from sqlalchemy.ext.asyncio import async_sessionmaker, AsyncSession
from sqlalchemy.orm import selectinload, DeclarativeBase, Mapped, mapped_column, relationship
from sqlalchemy import BigInteger, ForeignKey, Integer, String, TEXT

logger = logging.getLogger(__name__)

# --- å¼¹å¹•æ–‡ä»¶å­˜å‚¨é…ç½® ---
DANMAKU_BASE_DIR = Path(__file__).parent.parent / "config" / "danmaku"

# --- ä¸´æ—¶çš„ ORM æ¨¡å‹å®šä¹‰ï¼Œä»…ç”¨äºæ­¤è„šæœ¬ï¼Œä»¥é¿å…ä¸å·²ä¿®æ”¹çš„ä¸»æ¨¡å‹å†²çª ---
class TmpBase(DeclarativeBase):
    pass

class TmpAnime(TmpBase):
    __tablename__ = "anime"
    id: Mapped[int] = mapped_column(BigInteger, primary_key=True)
    sources: Mapped[List["TmpAnimeSource"]] = relationship(back_populates="anime")

class TmpAnimeSource(TmpBase):
    __tablename__ = "anime_sources"
    id: Mapped[int] = mapped_column(BigInteger, primary_key=True)
    animeId: Mapped[int] = mapped_column("anime_id", ForeignKey("anime.id"))
    episodes: Mapped[List["TmpEpisode"]] = relationship(back_populates="source")
    anime: Mapped["TmpAnime"] = relationship(back_populates="sources")

class TmpEpisode(TmpBase):
    __tablename__ = "episode"
    id: Mapped[int] = mapped_column(BigInteger, primary_key=True)
    sourceId: Mapped[int] = mapped_column("source_id", ForeignKey("anime_sources.id"))
    danmakuFilePath: Mapped[str] = mapped_column("danmaku_file_path", String(512), nullable=True)
    commentCount: Mapped[int] = mapped_column("comment_count", Integer)
    comments: Mapped[List["TmpComment"]] = relationship(back_populates="episode")
    source: Mapped["TmpAnimeSource"] = relationship(back_populates="episodes")

class TmpComment(TmpBase):
    __tablename__ = "comment"
    id: Mapped[int] = mapped_column(BigInteger, primary_key=True)
    episodeId: Mapped[int] = mapped_column("episode_id", ForeignKey("episode.id"))
    p: Mapped[str] = mapped_column(String(255))
    m: Mapped[str] = mapped_column(TEXT)
    episode: Mapped["TmpEpisode"] = relationship(back_populates="comments")

def _generate_xml_from_comments(comments: List[TmpComment], episode_id: int) -> str:
    """æ ¹æ®å¼¹å¹•å¯¹è±¡åˆ—è¡¨ç”Ÿæˆç¬¦åˆdandanplayæ ‡å‡†çš„XMLå­—ç¬¦ä¸²ã€‚"""
    root = ET.Element('i')
    ET.SubElement(root, 'chatserver').text = 'danmaku.misaka.org'
    ET.SubElement(root, 'chatid').text = str(episode_id)
    ET.SubElement(root, 'mission').text = '0'
    ET.SubElement(root, 'maxlimit').text = '2000'
    ET.SubElement(root, 'source').text = 'misaka'
    for comment in comments:
        ET.SubElement(root, 'd', p=comment.p).text = comment.m
    return ET.tostring(root, encoding='unicode', xml_declaration=True)

async def _add_danmaku_path_column_if_not_exists(session: AsyncSession):
    """å¦‚æœ episode è¡¨ä¸­ä¸å­˜åœ¨ danmaku_file_path åˆ—ï¼Œåˆ™æ·»åŠ å®ƒã€‚"""
    def check_columns_sync(conn):
        inspector = inspect(conn.connection())
        columns = inspector.get_columns('episode')
        return any(c['name'] == 'danmaku_file_path' for c in columns)

    has_column = await session.run_sync(check_columns_sync)

    if not has_column:
        logger.info("æ£€æµ‹åˆ° 'episode' è¡¨ä¸­ç¼ºå°‘ 'danmaku_file_path' åˆ—ï¼Œæ­£åœ¨æ·»åŠ ...")
        await session.execute(text("ALTER TABLE episode ADD COLUMN danmaku_file_path VARCHAR(512);"))
        await session.commit()
        logger.info("'danmaku_file_path' åˆ—å·²æˆåŠŸæ·»åŠ ã€‚")

async def run_db_migration(session_factory: async_sessionmaker[AsyncSession]):
    """
    åœ¨åº”ç”¨å¯åŠ¨æ—¶æ‰§è¡Œæ•°æ®åº“è¿ç§»ã€‚
    """
    logger.info("--- æ­£åœ¨æ£€æŸ¥æ•°æ®åº“è¿ç§»éœ€æ±‚ ---")
    async with session_factory() as session:
        def check_table_sync(conn):
            inspector = inspect(conn.connection())
            return inspector.has_table('comment')

        has_comment_table = await session.run_sync(check_table_sync)
        
        if not has_comment_table:
            logger.info("âœ… æœªæ‰¾åˆ° 'comment' è¡¨ï¼Œæ— éœ€è¿ç§»ã€‚")
            return

        logger.info("æ£€æµ‹åˆ°æ—§çš„ 'comment' è¡¨ï¼Œå°†å¼€å§‹æ‰§è¡Œæ•°æ®è¿ç§»...")

        # 1. ç¡®ä¿æ–°åˆ—å­˜åœ¨
        await _add_danmaku_path_column_if_not_exists(session)

        # 2. æŸ¥è¯¢æ‰€æœ‰éœ€è¦è¿ç§»çš„åˆ†é›†å’Œå¼¹å¹•
        logger.info("æ­£åœ¨æŸ¥è¯¢æ‰€æœ‰åˆ†é›†å’Œå…³è”çš„å¼¹å¹•æ•°æ®ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...")
        stmt = (
            select(TmpEpisode)
            .options(
                selectinload(TmpEpisode.comments),
                selectinload(TmpEpisode.source).selectinload(TmpAnimeSource.anime)
            )
            .where(TmpEpisode.comments.any(), TmpEpisode.danmakuFilePath == None)
        )
        result = await session.execute(stmt)
        episodes_to_migrate = result.scalars().unique().all()

        if not episodes_to_migrate:
            logger.info("âœ… æ•°æ®åº“ä¸­æ²¡æœ‰æ‰¾åˆ°éœ€è¦è¿ç§»çš„å¼¹å¹•æ•°æ®ã€‚")
            logger.info("æ­£åœ¨åˆ é™¤ç©ºçš„ 'comment' è¡¨...")
            await session.execute(text("DROP TABLE comment;"))
            await session.commit()
            logger.info("'comment' è¡¨å·²åˆ é™¤ã€‚")
            return

        logger.info(f"å…±æ‰¾åˆ° {len(episodes_to_migrate)} ä¸ªåˆ†é›†éœ€è¦è¿ç§»ã€‚")

        # 3. éå†å¹¶å¤„ç†æ¯ä¸ªåˆ†é›†
        migrated_count = 0
        try:
            for episode in episodes_to_migrate:
                if not episode.comments:
                    continue

                anime_id = episode.source.anime.id
                source_id = episode.source.id
                episode_id = episode.id

                # 4. ç”ŸæˆXMLå†…å®¹
                xml_content = _generate_xml_from_comments(episode.comments, episode_id)
                
                # 5. æ„å»ºæ–‡ä»¶è·¯å¾„å¹¶å†™å…¥
                web_path = f"/data/danmaku/{anime_id}/{source_id}/{episode_id}.xml"
                absolute_path = DANMAKU_BASE_DIR / str(anime_id) / str(source_id) / f"{episode_id}.xml"
                
                try:
                    absolute_path.parent.mkdir(parents=True, exist_ok=True)
                    absolute_path.write_text(xml_content, encoding='utf-8')
                except OSError as e:
                    logger.error(f"âŒ å†™å…¥æ–‡ä»¶å¤±è´¥: {absolute_path}ã€‚é”™è¯¯: {e}")
                    continue # è·³è¿‡è¿™ä¸ªåˆ†é›†

                # 6. æ›´æ–°æ•°æ®åº“è®°å½•
                episode.danmakuFilePath = web_path
                episode.commentCount = len(episode.comments)
                session.add(episode)
                migrated_count += 1
                if migrated_count % 100 == 0:
                    logger.info(f"å·²å¤„ç† {migrated_count}/{len(episodes_to_migrate)} ä¸ªåˆ†é›†...")
            
            # 7. æäº¤æ‰€æœ‰æ•°æ®åº“æ›´æ”¹
            logger.info("æ­£åœ¨å°†æ‰€æœ‰æ–‡ä»¶è·¯å¾„æ›´æ–°æäº¤åˆ°æ•°æ®åº“...")
            await session.commit()
            logger.info("æ•°æ®åº“æ›´æ–°å®Œæˆã€‚")

            # 8. åˆ é™¤æ—§çš„ comment è¡¨
            logger.info("æ­£åœ¨åˆ é™¤æ—§çš„ 'comment' è¡¨...")
            await session.execute(text("DROP TABLE comment;"))
            await session.commit()
            logger.info("'comment' è¡¨å·²æˆåŠŸåˆ é™¤ã€‚")

        except Exception as e:
            logger.error(f"è¿ç§»è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
            await session.rollback()
            logger.error("æ•°æ®åº“äº‹åŠ¡å·²å›æ»šã€‚è¯·æ£€æŸ¥é”™è¯¯å¹¶æ‰‹åŠ¨é‡æ–°è¿è¡Œè¿ç§»ã€‚")
            raise

    logger.info(f"ğŸ‰ --- å¼¹å¹•æ•°æ®è¿ç§»æˆåŠŸï¼å…±è¿ç§»äº† {migrated_count} ä¸ªåˆ†é›†çš„å¼¹å¹•ã€‚ ---")