"""Webhookä»»åŠ¡æ¨¡å—"""
import asyncio
import json
import logging
from typing import Callable, Optional, List
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from thefuzz import fuzz

from .. import crud, models, orm_models
from ..orm_models import AnimeSource as AS
from ..config_manager import ConfigManager
from ..scraper_manager import ScraperManager
from ..metadata_manager import MetadataSourceManager
from ..task_manager import TaskManager, TaskSuccess
from ..rate_limiter import RateLimiter
from ..title_recognition import TitleRecognitionManager
from ..search_utils import unified_search
from ..timezone import get_now
from ..utils import parse_search_keyword

logger = logging.getLogger(__name__)


# å»¶è¿Ÿå¯¼å…¥è¾…åŠ©å‡½æ•°
def _get_generic_import_task():
    from .import_core import generic_import_task
    return generic_import_task


async def run_webhook_tasks_directly_manual(
    session: AsyncSession,
    task_ids: List[int],
    task_manager: "TaskManager",
    scraper_manager: "ScraperManager",
    metadata_manager: "MetadataSourceManager",
    config_manager: "ConfigManager",
    rate_limiter: "RateLimiter",
    title_recognition_manager: "TitleRecognitionManager"
) -> int:
    """ç›´æ¥è·å–å¹¶æ‰§è¡ŒæŒ‡å®šçš„å¾…å¤„ç†Webhookä»»åŠ¡ã€‚"""
    if not task_ids:
        return 0

    stmt = select(orm_models.WebhookTask).where(orm_models.WebhookTask.id.in_(task_ids), orm_models.WebhookTask.status == "pending")
    tasks_to_run = (await session.execute(stmt)).scalars().all()

    submitted_count = 0
    for task in tasks_to_run:
        try:
            payload = json.loads(task.payload)
            task_coro = lambda s, cb: webhook_search_and_dispatch_task(
                webhookSource=task.webhookSource, progress_callback=cb, session=s,
                manager=scraper_manager, task_manager=task_manager,
                metadata_manager=metadata_manager, config_manager=config_manager,
                rate_limiter=rate_limiter, title_recognition_manager=title_recognition_manager,
                **payload
            )
            await task_manager.submit_task(task_coro, task.taskTitle, unique_key=task.uniqueKey)
            await session.delete(task)
            await session.commit()  # ä¸ºæ¯ä¸ªæˆåŠŸæäº¤çš„ä»»åŠ¡å•ç‹¬æäº¤åˆ é™¤æ“ä½œ
            submitted_count += 1
        except Exception as e:
            logger.error(f"æ‰‹åŠ¨æ‰§è¡Œ Webhook ä»»åŠ¡ (ID: {task.id}) æ—¶å¤±è´¥: {e}", exc_info=True)
            await session.rollback()
    return submitted_count


async def webhook_search_and_dispatch_task(
    animeTitle: str,
    mediaType: str,
    season: int,
    currentEpisodeIndex: int,
    searchKeyword: str,
    doubanId: Optional[str],
    tmdbId: Optional[str],
    imdbId: Optional[str],
    tvdbId: Optional[str],
    bangumiId: Optional[str],
    webhookSource: str,
    year: Optional[int],
    progress_callback: Callable,
    session: AsyncSession,
    manager: ScraperManager,
    task_manager: TaskManager, # type: ignore
    metadata_manager: MetadataSourceManager,
    config_manager: ConfigManager,
    rate_limiter: RateLimiter,
    title_recognition_manager: TitleRecognitionManager,
    # åª’ä½“åº“æ•´å­£å¯¼å…¥æ—¶, å¯é€‰: æŒ‡å®šå·²åœ¨åª’ä½“åº“ä¸­é€‰ä¸­çš„åˆ†é›†ç´¢å¼•åˆ—è¡¨
    selectedEpisodes: Optional[List[int]] = None,
):
    """
    Webhook è§¦å‘çš„åå°ä»»åŠ¡ï¼šæœç´¢æ‰€æœ‰æºï¼Œæ‰¾åˆ°æœ€ä½³åŒ¹é…ï¼Œå¹¶ä¸ºè¯¥åŒ¹é…åˆ†å‘ä¸€ä¸ªæ–°çš„ã€å…·ä½“çš„å¯¼å…¥ä»»åŠ¡ã€‚
    """
    generic_import_task = _get_generic_import_task()
    
    try:
        logger.info(f"Webhook ä»»åŠ¡: å¼€å§‹ä¸º '{animeTitle}' (S{season:02d}E{currentEpisodeIndex:02d}) æŸ¥æ‰¾æœ€ä½³æº...")
        await progress_callback(5, "æ­£åœ¨æ£€æŸ¥å·²æ”¶è—çš„æº...")

        # 1. ä¼˜å…ˆæŸ¥æ‰¾å·²æ”¶è—çš„æº (Favorited Source)
        logger.info(f"Webhook ä»»åŠ¡: æŸ¥æ‰¾å·²å­˜åœ¨çš„anime - æ ‡é¢˜='{animeTitle}', å­£æ•°={season}, å¹´ä»½={year}")
        existing_anime = await crud.find_anime_by_title_season_year(session, animeTitle, season, year, title_recognition_manager, source=None)
        if existing_anime:
            anime_id = existing_anime['id']
            favorited_source = await crud.find_favorited_source_for_anime(session, anime_id)
            if favorited_source:
                logger.info(f"Webhook ä»»åŠ¡: æ‰¾åˆ°å·²æ”¶è—çš„æº '{favorited_source['providerName']}'ï¼Œå°†ç›´æ¥ä½¿ç”¨æ­¤æºã€‚")
                await progress_callback(10, f"æ‰¾åˆ°å·²æ”¶è—çš„æº: {favorited_source['providerName']}")

                # æ ¹æ®æ¥æºåŠ¨æ€ç”Ÿæˆä»»åŠ¡æ ‡é¢˜å‰ç¼€
                if webhookSource == "media_server":
                    source_prefix = "åª’ä½“åº“è¯»å–å¯¼å…¥"
                elif webhookSource in ["emby", "jellyfin", "plex"]:
                    source_prefix = f"Webhookè‡ªåŠ¨å¯¼å…¥ ({webhookSource.capitalize()})"
                else:
                    source_prefix = f"Webhookè‡ªåŠ¨å¯¼å…¥ ({webhookSource})"

                task_title = f"{source_prefix}: {favorited_source['animeTitle']} - S{season:02d}E{currentEpisodeIndex:02d} ({favorited_source['providerName']})"
                unique_key = f"import-{favorited_source['providerName']}-{favorited_source['mediaId']}-S{season}-ep{currentEpisodeIndex}"
                task_coro = lambda session, cb: generic_import_task(
                    provider=favorited_source['providerName'], mediaId=favorited_source['mediaId'], animeTitle=favorited_source['animeTitle'], year=year,
                    mediaType=favorited_source['mediaType'], season=season, currentEpisodeIndex=currentEpisodeIndex,
                    imageUrl=favorited_source['imageUrl'], doubanId=doubanId, tmdbId=tmdbId, imdbId=imdbId, tvdbId=tvdbId, config_manager=config_manager, metadata_manager=metadata_manager,
                    bangumiId=bangumiId, rate_limiter=rate_limiter,
                    progress_callback=cb, session=session, manager=manager,
                    task_manager=task_manager,
                    title_recognition_manager=title_recognition_manager,
                    selectedEpisodes=selectedEpisodes,
                )
                await task_manager.submit_task(task_coro, task_title, unique_key=unique_key)

                # æ ¹æ®æ¥æºåŠ¨æ€ç”ŸæˆæˆåŠŸæ¶ˆæ¯
                if webhookSource == "media_server":
                    success_message = f"å·²ä¸ºæ”¶è—æº '{favorited_source['providerName']}' åˆ›å»ºå¯¼å…¥ä»»åŠ¡ã€‚"
                else:
                    success_message = f"Webhook: å·²ä¸ºæ”¶è—æº '{favorited_source['providerName']}' åˆ›å»ºå¯¼å…¥ä»»åŠ¡ã€‚"
                raise TaskSuccess(success_message)

        # 2. å¦‚æœæ²¡æœ‰æ”¶è—æºï¼Œåˆ™å¹¶å‘æœç´¢æ‰€æœ‰å¯ç”¨çš„æº
        logger.info(f"Webhook ä»»åŠ¡: æœªæ‰¾åˆ°æ”¶è—æºï¼Œå¼€å§‹å¹¶å‘æœç´¢æ‰€æœ‰å¯ç”¨çš„æº...")
        await progress_callback(20, "å¹¶å‘æœç´¢æ‰€æœ‰æº...")

        parsed_keyword = parse_search_keyword(searchKeyword)
        original_title = parsed_keyword["title"]
        season_to_filter = parsed_keyword.get("season") or season
        episode_to_filter = parsed_keyword.get("episode") or currentEpisodeIndex

        # 2.1 åˆ›å»ºå­£åº¦æ˜ å°„ä»»åŠ¡(å¦‚æœå¯ç”¨) - ä¸æœç´¢å¹¶è¡Œè¿è¡Œ
        season_mapping_task = None
        webhook_tmdb_enabled = await config_manager.get("webhookEnableTmdbSeasonMapping", "true")
        if webhook_tmdb_enabled.lower() == "true" and season_to_filter and season_to_filter > 1:
            logger.info(f"â—‹ Webhook å­£åº¦æ˜ å°„: å¼€å§‹ä¸º '{original_title}' S{season_to_filter:02d} è·å–å­£åº¦åç§°(å¹¶è¡Œ)...")

            # æ£€æŸ¥æ˜¯å¦å¯ç”¨AIåŒ¹é…
            ai_match_enabled = await config_manager.get("aiMatchEnabled", "false")
            ai_matcher = None
            if ai_match_enabled.lower() == "true":
                try:
                    from ..ai_matcher import AIMatcher
                    ai_config = {
                        "ai_match_provider": await config_manager.get("aiProvider", "deepseek"),
                        "ai_match_api_key": await config_manager.get("aiApiKey", ""),
                        "ai_match_base_url": await config_manager.get("aiBaseUrl", ""),
                        "ai_match_model": await config_manager.get("aiModel", "deepseek-chat"),
                        "ai_match_prompt": await config_manager.get("aiPrompt", ""),
                        "ai_log_raw_response": (await config_manager.get("aiLogRawResponse", "false")).lower() == "true"
                    }
                    ai_matcher = AIMatcher(ai_config)
                except Exception as e:
                    logger.warning(f"Webhook å­£åº¦æ˜ å°„: AIåŒ¹é…å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

            # è·å–å…ƒæ•°æ®æºå’Œè‡ªå®šä¹‰æç¤ºè¯
            metadata_source = await config_manager.get("seasonMappingMetadataSource", "tmdb")
            custom_prompt = await config_manager.get("seasonMappingPrompt", "")
            sources = [metadata_source] if metadata_source else None

            # åˆ›å»ºå¹¶è¡Œä»»åŠ¡
            async def get_season_mapping():
                try:
                    return await metadata_manager.get_season_name(
                        title=original_title,
                        season_number=season_to_filter,
                        year=year,
                        sources=sources,
                        ai_matcher=ai_matcher,
                        user=None,
                        custom_prompt=custom_prompt if custom_prompt else None
                    )
                except Exception as e:
                    logger.warning(f"Webhook å­£åº¦æ˜ å°„å¤±è´¥: {e}")
                    return None

            season_mapping_task = asyncio.create_task(get_season_mapping())
        else:
            if webhook_tmdb_enabled.lower() != "true":
                logger.info("â—‹ Webhook å­£åº¦æ˜ å°„: åŠŸèƒ½æœªå¯ç”¨")
            elif not season_to_filter or season_to_filter <= 1:
                logger.info(f"â—‹ Webhook å­£åº¦æ˜ å°„: å­£åº¦å·ä¸º{season_to_filter},è·³è¿‡(ä»…å¤„ç†S02åŠä»¥ä¸Š)")

        # åº”ç”¨ä¸ WebUI ä¸€è‡´çš„æ ‡é¢˜é¢„å¤„ç†è§„åˆ™
        search_title = original_title
        if title_recognition_manager:
            (
                processed_title,
                processed_episode,
                processed_season,
                preprocessing_applied,
            ) = await title_recognition_manager.apply_search_preprocessing(
                original_title, episode_to_filter, season_to_filter
            )
            if preprocessing_applied:
                search_title = processed_title
                logger.info(
                    f"âœ“ Webhookæœç´¢é¢„å¤„ç†: '{original_title}' -> '{search_title}'"
                )
                if processed_episode != episode_to_filter:
                    logger.info(
                        f"âœ“ Webhooké›†æ•°é¢„å¤„ç†: {episode_to_filter} -> {processed_episode}"
                    )
                    episode_to_filter = processed_episode
                if processed_season != season_to_filter:
                    logger.info(
                        f"âœ“ Webhookå­£åº¦é¢„å¤„ç†: {season_to_filter} -> {processed_season}"
                    )
                    season_to_filter = processed_season
            else:
                logger.info(f"â—‹ Webhookæœç´¢é¢„å¤„ç†æœªç”Ÿæ•ˆ: '{original_title}'")
        else:
            logger.info("â—‹ æœªé…ç½®æ ‡é¢˜è¯†åˆ«ç®¡ç†å™¨ï¼Œè·³è¿‡Webhookæœç´¢é¢„å¤„ç†ã€‚")

        # æ„é€  episode_info
        episode_info = (
            {"season": season_to_filter, "episode": episode_to_filter}
            if episode_to_filter is not None
            else {"season": season_to_filter}
        )

        logger.info(f"Webhook ä»»åŠ¡: å·²å°†æœç´¢è¯ '{searchKeyword}' è§£æä¸ºæ ‡é¢˜ '{search_title}' è¿›è¡Œæœç´¢ã€‚")

        # ä½¿ç”¨ç»Ÿä¸€çš„æœç´¢å‡½æ•°ï¼ˆä¸ WebUI æœç´¢ä¿æŒä¸€è‡´ï¼‰
        all_search_results = await unified_search(
            search_term=search_title,
            session=session,
            scraper_manager=manager,
            metadata_manager=metadata_manager,
            use_alias_expansion=True,
            use_alias_filtering=True,
            use_title_filtering=True,
            use_source_priority_sorting=True,
            progress_callback=None,
            episode_info=episode_info,
            alias_similarity_threshold=70,
        )

        if not all_search_results:
            raise ValueError(f"æœªæ‰¾åˆ° '{animeTitle}' çš„ä»»ä½•å¯ç”¨æºã€‚")

        # ç­‰å¾…å­£åº¦æ˜ å°„ä»»åŠ¡å®Œæˆ(å¦‚æœæœ‰)
        season_name_from_mapping = None
        if season_mapping_task:
            try:
                season_name_from_mapping = await season_mapping_task
                if season_name_from_mapping:
                    logger.info(f"âœ“ Webhook å­£åº¦æ˜ å°„æˆåŠŸ: '{original_title}' S{season_to_filter:02d} â†’ '{season_name_from_mapping}'")
                else:
                    logger.info(f"â—‹ Webhook å­£åº¦æ˜ å°„: æœªæ‰¾åˆ°å­£åº¦åç§°")
            except Exception as e:
                logger.warning(f"Webhook å­£åº¦æ˜ å°„ä»»åŠ¡å¤±è´¥: {e}")

        # æ ¹æ®å­£åº¦æ˜ å°„ç»“æœè°ƒæ•´æœç´¢ç»“æœçš„ season å­—æ®µ
        if season_name_from_mapping and season_to_filter and season_to_filter > 1:
            from ..season_mapper import title_contains_season_name

            adjusted_count = 0
            for item in all_search_results:
                # åªå¤„ç†ç”µè§†å‰§ç±»å‹ä¸” season ä¸º None æˆ– 1 çš„ç»“æœ
                if item.type == "tv_series" and (item.season is None or item.season == 1):
                    if title_contains_season_name(item.title, season_name_from_mapping, threshold=60.0):
                        logger.info(f"  âœ“ å­£åº¦è°ƒæ•´: '{item.title}' (Provider: {item.provider}) season: {item.season} â†’ {season_to_filter}")
                        item.season = season_to_filter
                        adjusted_count += 1

            if adjusted_count > 0:
                logger.info(f"âœ“ æ ¹æ®å­£åº¦æ˜ å°„è°ƒæ•´äº† {adjusted_count} ä¸ªç»“æœçš„ season å­—æ®µ")

        # 3. æ ¹æ®æ ‡é¢˜å…³é”®è¯ä¿®æ­£åª’ä½“ç±»å‹ï¼ˆä¸ WebUI ä¸€è‡´ï¼‰
        def is_movie_by_title(title: str) -> bool:
            if not title:
                return False
            # å…³é”®è¯åˆ—è¡¨ï¼Œä¸åŒºåˆ†å¤§å°å†™
            movie_keywords = ["å‰§åœºç‰ˆ", "åŠ‡å ´ç‰ˆ", "movie", "æ˜ ç”»"]
            title_lower = title.lower()
            return any(keyword in title_lower for keyword in movie_keywords)

        for item in all_search_results:
            if item.type == "tv_series" and is_movie_by_title(item.title):
                logger.info(
                    f"Webhook: æ ‡é¢˜ '{item.title}' åŒ…å«ç”µå½±å…³é”®è¯ï¼Œç±»å‹ä» 'tv_series' ä¿®æ­£ä¸º 'movie'ã€‚"
                )
                item.type = "movie"

        # 4. å¦‚æœæœç´¢è¯ä¸­æ˜ç¡®æŒ‡å®šäº†å­£åº¦ï¼Œå¯¹ç»“æœè¿›è¡Œè¿‡æ»¤ï¼ˆä¸ WebUI ä¸€è‡´ï¼‰
        # æ³¨æ„ï¼šç”µå½±ç±»å‹ä¸è¿›è¡Œå­£åº¦è¿‡æ»¤
        if season_to_filter and season_to_filter > 0 and mediaType != "movie":
            original_count = len(all_search_results)
            # å½“æŒ‡å®šå­£åº¦æ—¶ï¼Œæˆ‘ä»¬åªå…³å¿ƒç”µè§†å‰§ç±»å‹
            filtered_by_type = [item for item in all_search_results if item.type == "tv_series"]

            # ç„¶ååœ¨ç”µè§†å‰§ç±»å‹ä¸­ï¼Œæˆ‘ä»¬æŒ‰å­£åº¦å·è¿‡æ»¤
            filtered_by_season = [
                item for item in filtered_by_type if item.season == season_to_filter
            ]

            logger.info(
                f"Webhook: æ ¹æ®æŒ‡å®šçš„å­£åº¦ ({season_to_filter}) è¿›è¡Œè¿‡æ»¤ï¼Œä» {original_count} ä¸ªç»“æœä¸­ä¿ç•™äº† {len(filtered_by_season)} ä¸ªã€‚"
            )
            all_search_results = filtered_by_season

        # 5. ä½¿ç”¨ä¸WebUIç›¸åŒçš„æ™ºèƒ½åŒ¹é…ç®—æ³•é€‰æ‹©æœ€ä½³åŒ¹é…é¡¹
        ordered_settings = await crud.get_all_scraper_settings(session)
        provider_order = {s['providerName']: s['displayOrder'] for s in ordered_settings}

        # æ·»åŠ è°ƒè¯•æ—¥å¿—
        logger.info(f"Webhook ä»»åŠ¡: æ’åºå‰çš„åª’ä½“ç±»å‹: media_type='{mediaType}', å…± {len(all_search_results)} ä¸ªç»“æœ")
        for i, item in enumerate(all_search_results[:5]):
            logger.info(f"  {i+1}. '{item.title}' (Provider: {item.provider}, Type: {item.type})")

        # ä½¿ç”¨ä¸WebUIç›¸åŒçš„æ™ºèƒ½æ’åºé€»è¾‘ï¼Œä¼˜åŒ–å¹´ä»½æƒé‡
        all_search_results.sort(
            key=lambda item: (
                # 1. æœ€é«˜ä¼˜å…ˆçº§ï¼šå®Œå…¨åŒ¹é…çš„æ ‡é¢˜
                10000 if item.title.strip() == animeTitle.strip() else 0,
                # 2. æ¬¡é«˜ä¼˜å…ˆçº§ï¼šå»é™¤æ ‡ç‚¹ç¬¦å·åçš„å®Œå…¨åŒ¹é…
                5000 if item.title.replace("ï¼š", ":").replace(" ", "").strip() == animeTitle.replace("ï¼š", ":").replace(" ", "").strip() else 0,
                # 3. ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šé«˜ç›¸ä¼¼åº¦åŒ¹é…ï¼ˆ98%ä»¥ä¸Šï¼‰ä¸”æ ‡é¢˜é•¿åº¦å·®å¼‚ä¸å¤§
                2000 if (fuzz.token_sort_ratio(animeTitle, item.title) > 98 and abs(len(item.title) - len(animeTitle)) <= 10) else 0,
                # 4. ç¬¬å››ä¼˜å…ˆçº§ï¼šè¾ƒé«˜ç›¸ä¼¼åº¦åŒ¹é…ï¼ˆ95%ä»¥ä¸Šï¼‰ä¸”æ ‡é¢˜é•¿åº¦å·®å¼‚ä¸å¤§
                1000 if (fuzz.token_sort_ratio(animeTitle, item.title) > 95 and abs(len(item.title) - len(animeTitle)) <= 20) else 0,
                # 5. å¹´ä»½åŒ¹é…ï¼ˆé™ä½æƒé‡ï¼Œé¿å…å¹´ä»½åŒ¹é…ä½†æ ‡é¢˜ä¸åŒ¹é…çš„ç»“æœæ’åœ¨å‰é¢ï¼‰
                500 if year is not None and item.year is not None and item.year == year else 0,
                # 6. å­£åº¦åŒ¹é…ï¼ˆä»…å¯¹ç”µè§†å‰§ï¼‰
                100 if season is not None and mediaType == 'tv_series' and item.season == season else 0,
                # 7. ä¸€èˆ¬ç›¸ä¼¼åº¦ï¼Œä½†å¿…é¡»è¾¾åˆ°85%ä»¥ä¸Šæ‰è€ƒè™‘
                fuzz.token_set_ratio(animeTitle, item.title) if fuzz.token_set_ratio(animeTitle, item.title) >= 85 else 0,
                # 8. æƒ©ç½šæ ‡é¢˜é•¿åº¦å·®å¼‚å¤§çš„ç»“æœ
                -abs(len(item.title) - len(animeTitle)),
                # 9. æƒ©ç½šå¹´ä»½ä¸åŒ¹é…çš„ç»“æœï¼ˆå¦‚æœwebhookæä¾›äº†å¹´ä»½ä½†æœç´¢ç»“æœå¹´ä»½ä¸åŒ¹é…ï¼‰
                -500 if year is not None and item.year is not None and item.year != year else 0,
                # 10. æœ€åè€ƒè™‘æºä¼˜å…ˆçº§
                -provider_order.get(item.provider, 999)
            ),
            reverse=True # æŒ‰å¾—åˆ†ä»é«˜åˆ°ä½æ’åº
        )

        # æ·»åŠ æ’åºåçš„è°ƒè¯•æ—¥å¿—
        logger.info(f"Webhook ä»»åŠ¡: æ’åºåçš„å‰5ä¸ªç»“æœ:")
        for i, item in enumerate(all_search_results[:5]):
            title_match = "âœ“" if item.title.strip() == animeTitle.strip() else "âœ—"
            year_match = "âœ“" if year is not None and item.year is not None and item.year == year else ("âœ—" if year is not None and item.year is not None else "-")
            similarity = fuzz.token_set_ratio(animeTitle, item.title)
            year_info = f"å¹´ä»½: {item.year}" if item.year else "å¹´ä»½: æœªçŸ¥"
            logger.info(f"  {i+1}. '{item.title}' (Provider: {item.provider}, Type: {item.type}, {year_info}, å¹´ä»½åŒ¹é…: {year_match}, æ ‡é¢˜åŒ¹é…: {title_match}, ç›¸ä¼¼åº¦: {similarity}%)")

        # è¯„ä¼°æ‰€æœ‰å€™é€‰é¡¹ (ä¸é™åˆ¶æ•°é‡)
        logger.info(f"Webhook ä»»åŠ¡: å…±æœ‰ {len(all_search_results)} ä¸ªæœç´¢ç»“æœ")

        # æ£€æŸ¥æ˜¯å¦å¯ç”¨AIåŒ¹é…
        ai_match_enabled = (await config_manager.get("aiMatchEnabled", "false")).lower() == 'true'
        best_match = None
        ai_selected_index = None

        if ai_match_enabled:
            logger.info("Webhook ä»»åŠ¡: AIåŒ¹é…å·²å¯ç”¨")
            try:
                # è·å–AIé…ç½® - ä½¿ç”¨ AIMatcher æœŸæœ›çš„é”®å
                ai_config = {
                    'ai_match_provider': await config_manager.get("aiProvider", "deepseek"),
                    'ai_match_api_key': await config_manager.get("aiApiKey", ""),
                    'ai_match_base_url': await config_manager.get("aiBaseUrl", ""),
                    'ai_match_model': await config_manager.get("aiModel", ""),
                    'ai_match_prompt': await config_manager.get("aiPrompt", ""),
                    'ai_log_raw_response': (await config_manager.get("aiLogRawResponse", "false")).lower() == 'true'
                }

                # æ£€æŸ¥å¿…è¦é…ç½®
                if not ai_config['ai_match_api_key']:
                    logger.warning("Webhook ä»»åŠ¡: AIåŒ¹é…å·²å¯ç”¨ä½†æœªé…ç½®APIå¯†é’¥ï¼Œé™çº§åˆ°ä¼ ç»ŸåŒ¹é…")
                else:
                    # æ„å»ºæŸ¥è¯¢ä¿¡æ¯
                    query_info = {
                        'title': animeTitle,
                        'season': season if mediaType == 'tv_series' else None,
                        'episode': currentEpisodeIndex,
                        'year': year,
                        'type': mediaType
                    }

                    # è·å–ç²¾ç¡®æ ‡è®°ä¿¡æ¯
                    favorited_info = {}

                    for result in all_search_results:
                        # æŸ¥æ‰¾æ˜¯å¦æœ‰ç›¸åŒproviderå’ŒmediaIdçš„æºè¢«æ ‡è®°
                        stmt = (
                            select(AS.isFavorited)
                            .where(
                                AS.providerName == result.provider,
                                AS.mediaId == result.mediaId
                            )
                            .limit(1)
                        )
                        result_row = await session.execute(stmt)
                        is_favorited = result_row.scalar_one_or_none()
                        if is_favorited:
                            key = f"{result.provider}:{result.mediaId}"
                            favorited_info[key] = True

                    # åˆå§‹åŒ–AIåŒ¹é…å™¨å¹¶é€‰æ‹©
                    from ..ai_matcher import AIMatcher
                    matcher = AIMatcher(ai_config)
                    ai_selected_index = await matcher.select_best_match(
                        query_info, all_search_results, favorited_info
                    )

                if ai_selected_index is not None:
                    best_match = all_search_results[ai_selected_index]
                    logger.info(f"Webhook ä»»åŠ¡: AIåŒ¹é…æˆåŠŸé€‰æ‹©: {best_match.provider} - {best_match.title}")
                else:
                    # æ£€æŸ¥æ˜¯å¦å¯ç”¨ä¼ ç»ŸåŒ¹é…å…œåº•
                    ai_fallback_enabled = (await config_manager.get("aiFallbackEnabled", "true")).lower() == 'true'
                    if ai_fallback_enabled:
                        logger.info("Webhook ä»»åŠ¡: AIåŒ¹é…æœªæ‰¾åˆ°åˆé€‚ç»“æœï¼Œé™çº§åˆ°ä¼ ç»ŸåŒ¹é…")
                    else:
                        logger.warning("Webhook ä»»åŠ¡: AIåŒ¹é…æœªæ‰¾åˆ°åˆé€‚ç»“æœï¼Œä¸”ä¼ ç»ŸåŒ¹é…å…œåº•å·²ç¦ç”¨")
                        raise ValueError("AIåŒ¹é…å¤±è´¥ä¸”ä¼ ç»ŸåŒ¹é…å…œåº•å·²ç¦ç”¨")

            except Exception as e:
                # æ£€æŸ¥æ˜¯å¦å¯ç”¨ä¼ ç»ŸåŒ¹é…å…œåº•
                ai_fallback_enabled = (await config_manager.get("aiFallbackEnabled", "true")).lower() == 'true'
                if ai_fallback_enabled:
                    logger.error(f"Webhook ä»»åŠ¡: AIåŒ¹é…å¤±è´¥ï¼Œé™çº§åˆ°ä¼ ç»ŸåŒ¹é…: {e}")
                else:
                    logger.error(f"Webhook ä»»åŠ¡: AIåŒ¹é…å¤±è´¥ï¼Œä¸”ä¼ ç»ŸåŒ¹é…å…œåº•å·²ç¦ç”¨: {e}")
                    raise ValueError(f"AIåŒ¹é…å¤±è´¥ä¸”ä¼ ç»ŸåŒ¹é…å…œåº•å·²ç¦ç”¨: {e}")
                ai_selected_index = None

        # å¦‚æœAIé€‰æ‹©æˆåŠŸï¼Œä½¿ç”¨AIé€‰æ‹©çš„ç»“æœ
        if best_match is not None:
            logger.info(f"Webhook ä»»åŠ¡: ä½¿ç”¨AIé€‰æ‹©çš„ç»“æœ: {best_match.provider} - {best_match.title}")
            await progress_callback(50, f"åœ¨ {best_match.provider} ä¸­æ‰¾åˆ°æœ€ä½³åŒ¹é…é¡¹")

            current_time = get_now().strftime("%H:%M:%S")
            # æ ¹æ®æ¥æºåŠ¨æ€ç”Ÿæˆä»»åŠ¡æ ‡é¢˜å‰ç¼€
            if webhookSource == "media_server":
                source_prefix = "åª’ä½“åº“è¯»å–å¯¼å…¥"
            elif webhookSource in ["emby", "jellyfin", "plex"]:
                source_prefix = f"Webhookè‡ªåŠ¨å¯¼å…¥ ({webhookSource.capitalize()})"
            else:
                source_prefix = f"Webhookè‡ªåŠ¨å¯¼å…¥ ({webhookSource})"

            if mediaType == "tv_series":
                task_title = f"{source_prefix}: {best_match.title} - S{season:02d}E{currentEpisodeIndex:02d} ({best_match.provider}) [{current_time}]"
            else:
                task_title = f"{source_prefix}: {best_match.title} ({best_match.provider}) [{current_time}]"
            unique_key = f"import-{best_match.provider}-{best_match.mediaId}-S{season}-ep{currentEpisodeIndex}"

            # ä¿®æ­£ï¼šä¼˜å…ˆä½¿ç”¨æœç´¢ç»“æœçš„å¹´ä»½ï¼Œå¦‚æœæœç´¢ç»“æœæ²¡æœ‰å¹´ä»½åˆ™ä½¿ç”¨webhookä¼ å…¥çš„å¹´ä»½
            final_year = best_match.year if best_match.year is not None else year
            task_coro = lambda session, cb: generic_import_task(
                provider=best_match.provider, mediaId=best_match.mediaId, year=final_year,
                animeTitle=best_match.title, mediaType=best_match.type,
                season=season, currentEpisodeIndex=currentEpisodeIndex, imageUrl=best_match.imageUrl, config_manager=config_manager, metadata_manager=metadata_manager,
                doubanId=doubanId, tmdbId=tmdbId, imdbId=imdbId, tvdbId=tvdbId, bangumiId=bangumiId, rate_limiter=rate_limiter,
                progress_callback=cb, session=session, manager=manager,
                task_manager=task_manager,
                title_recognition_manager=title_recognition_manager,
                selectedEpisodes=selectedEpisodes,
            )
            await task_manager.submit_task(task_coro, task_title, unique_key=unique_key)

            # æ ¹æ®æ¥æºåŠ¨æ€ç”ŸæˆæˆåŠŸæ¶ˆæ¯
            if webhookSource == "media_server":
                success_message = f"å·²ä¸ºæº '{best_match.provider}' åˆ›å»ºå¯¼å…¥ä»»åŠ¡ã€‚"
            else:
                success_message = f"Webhook: å·²ä¸ºæº '{best_match.provider}' åˆ›å»ºå¯¼å…¥ä»»åŠ¡ã€‚"
            raise TaskSuccess(success_message)

        # ä¼ ç»ŸåŒ¹é…: ä¼˜å…ˆæŸ¥æ‰¾ç²¾ç¡®æ ‡è®°æº (éœ€éªŒè¯æ ‡é¢˜ç›¸ä¼¼åº¦)
        favorited_match = None

        for result in all_search_results:
            # æŸ¥æ‰¾æ˜¯å¦æœ‰ç›¸åŒproviderå’ŒmediaIdçš„æºè¢«æ ‡è®°
            stmt = (
                select(AS.isFavorited)
                .where(
                    AS.providerName == result.provider,
                    AS.mediaId == result.mediaId
                )
                .limit(1)
            )
            result_row = await session.execute(stmt)
            is_favorited = result_row.scalar_one_or_none()
            if is_favorited:
                # éªŒè¯æ ‡é¢˜ç›¸ä¼¼åº¦,é¿å…é”™è¯¯åŒ¹é…
                similarity = fuzz.token_set_ratio(animeTitle, result.title)
                logger.info(f"Webhook ä»»åŠ¡: æ‰¾åˆ°ç²¾ç¡®æ ‡è®°æº: {result.provider} - {result.title} (ç›¸ä¼¼åº¦: {similarity}%)")

                # åªæœ‰ç›¸ä¼¼åº¦ >= 60% æ‰ä½¿ç”¨ç²¾ç¡®æ ‡è®°æº
                if similarity >= 60:
                    favorited_match = result
                    logger.info(f"Webhook ä»»åŠ¡: æ ‡é¢˜ç›¸ä¼¼åº¦éªŒè¯é€šè¿‡ ({similarity}% >= 60%)")
                    break
                else:
                    logger.warning(f"Webhook ä»»åŠ¡: æ ‡é¢˜ç›¸ä¼¼åº¦è¿‡ä½ ({similarity}% < 60%)ï¼Œè·³è¿‡æ­¤ç²¾ç¡®æ ‡è®°æº")

        # æ£€æŸ¥æ˜¯å¦å¯ç”¨é¡ºå»¶æœºåˆ¶
        fallback_enabled = (await config_manager.get("webhookFallbackEnabled", "false")).lower() == 'true'

        if favorited_match:
            best_match = favorited_match
            logger.info(f"Webhook ä»»åŠ¡: ä½¿ç”¨ç²¾ç¡®æ ‡è®°æº: {best_match.provider} - {best_match.title}")
        elif not fallback_enabled:
            # é¡ºå»¶æœºåˆ¶å…³é—­ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªç»“æœ (å·²ç»æ˜¯åˆ†æ•°æœ€é«˜çš„)
            if all_search_results:
                best_match = all_search_results[0]
                logger.info(f"Webhook ä»»åŠ¡: é¡ºå»¶æœºåˆ¶å·²å…³é—­ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªç»“æœ: {best_match.provider} - {best_match.title}")
            else:
                logger.warning(f"Webhook ä»»åŠ¡: é¡ºå»¶æœºåˆ¶å·²å…³é—­ï¼Œä½†æœç´¢ç»“æœä¸ºç©ºï¼Œæ— æ³•é€‰æ‹©ç»“æœ")

        if best_match is not None:
            await progress_callback(50, f"åœ¨ {best_match.provider} ä¸­æ‰¾åˆ°æœ€ä½³åŒ¹é…é¡¹")

            current_time = get_now().strftime("%H:%M:%S")
            # æ ¹æ®æ¥æºåŠ¨æ€ç”Ÿæˆä»»åŠ¡æ ‡é¢˜å‰ç¼€
            if webhookSource == "media_server":
                source_prefix = "åª’ä½“åº“è¯»å–å¯¼å…¥"
            elif webhookSource in ["emby", "jellyfin", "plex"]:
                source_prefix = f"Webhookè‡ªåŠ¨å¯¼å…¥ ({webhookSource.capitalize()})"
            else:
                source_prefix = f"Webhookè‡ªåŠ¨å¯¼å…¥ ({webhookSource})"

            if mediaType == "tv_series":
                task_title = f"{source_prefix}: {best_match.title} - S{season:02d}E{currentEpisodeIndex:02d} ({best_match.provider}) [{current_time}]"
            else:
                task_title = f"{source_prefix}: {best_match.title} ({best_match.provider}) [{current_time}]"
            unique_key = f"import-{best_match.provider}-{best_match.mediaId}-S{season}-ep{currentEpisodeIndex}"

            # ä¿®æ­£ï¼šä¼˜å…ˆä½¿ç”¨æœç´¢ç»“æœçš„å¹´ä»½ï¼Œå¦‚æœæœç´¢ç»“æœæ²¡æœ‰å¹´ä»½åˆ™ä½¿ç”¨webhookä¼ å…¥çš„å¹´ä»½
            final_year = best_match.year if best_match.year is not None else year
            task_coro = lambda session, cb: generic_import_task(
                provider=best_match.provider, mediaId=best_match.mediaId, year=final_year,
                animeTitle=best_match.title, mediaType=best_match.type,
                season=season, currentEpisodeIndex=currentEpisodeIndex, imageUrl=best_match.imageUrl, config_manager=config_manager, metadata_manager=metadata_manager,
                doubanId=doubanId, tmdbId=tmdbId, imdbId=imdbId, tvdbId=tvdbId, bangumiId=bangumiId, rate_limiter=rate_limiter,
                progress_callback=cb, session=session, manager=manager,
                task_manager=task_manager,
                title_recognition_manager=title_recognition_manager,
                selectedEpisodes=selectedEpisodes,
            )
            await task_manager.submit_task(task_coro, task_title, unique_key=unique_key)

            # æ ¹æ®æ¥æºåŠ¨æ€ç”ŸæˆæˆåŠŸæ¶ˆæ¯
            if webhookSource == "media_server":
                success_message = f"å·²ä¸ºæº '{best_match.provider}' åˆ›å»ºå¯¼å…¥ä»»åŠ¡ã€‚"
            else:
                success_message = f"Webhook: å·²ä¸ºæº '{best_match.provider}' åˆ›å»ºå¯¼å…¥ä»»åŠ¡ã€‚"
            raise TaskSuccess(success_message)

        # é¡ºå»¶æœºåˆ¶å¯ç”¨ï¼šä¾æ¬¡éªŒè¯å€™é€‰æº (æŒ‰åˆ†æ•°ä»é«˜åˆ°ä½)
        logger.info(f"ğŸ”„ Webhook é¡ºå»¶æœºåˆ¶: å·²å¯ç”¨ï¼Œå…±æœ‰ {len(all_search_results)} ä¸ªå€™é€‰æºå¾…éªŒè¯")
        for attempt, candidate in enumerate(all_search_results, 1):
            logger.info(f"â†’ [{attempt}/{len(all_search_results)}] æ­£åœ¨éªŒè¯: {candidate.provider} - {candidate.title} (ID: {candidate.mediaId}, ç±»å‹: {candidate.type})")
            try:
                scraper = manager.get_scraper(candidate.provider)
                if not scraper:
                    logger.warning(f"    {attempt}. {candidate.provider} - æ— æ³•è·å–scraperï¼Œè·³è¿‡")
                    continue

                # è·å–åˆ†é›†åˆ—è¡¨è¿›è¡ŒéªŒè¯
                episodes = await scraper.get_episodes(candidate.mediaId, db_media_type=candidate.type)
                if not episodes:
                    logger.warning(f"    {attempt}. {candidate.provider} - æ²¡æœ‰åˆ†é›†åˆ—è¡¨ï¼Œè·³è¿‡")
                    continue

                # å¦‚æœæ˜¯ç”µå½±ï¼ŒåªåŒ¹é…ç”µå½±ç±»å‹çš„å€™é€‰æº
                if mediaType == "movie":
                    if candidate.type != "movie":
                        logger.warning(f"    {attempt}. {candidate.provider} - ç±»å‹ä¸åŒ¹é… (æœç´¢ç”µå½±ï¼Œä½†å€™é€‰æºæ˜¯{candidate.type})ï¼Œè·³è¿‡")
                        continue
                    logger.info(f"    {attempt}. {candidate.provider} - éªŒè¯é€šè¿‡ (ç”µå½±)")
                # å¦‚æœæ˜¯ç”µè§†å‰§ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ç›®æ ‡é›†æ•°
                else:
                    target_episode = None
                    for ep in episodes:
                        if ep.episodeIndex == currentEpisodeIndex:
                            target_episode = ep
                            break

                    if not target_episode:
                        logger.warning(f"    {attempt}. {candidate.provider} - æ²¡æœ‰ç¬¬ {currentEpisodeIndex} é›†ï¼Œè·³è¿‡")
                        continue

                    logger.info(f"    {attempt}. {candidate.provider} - éªŒè¯é€šè¿‡")

                best_match = candidate
                break
            except Exception as e:
                logger.warning(f"    {attempt}. {candidate.provider} - éªŒè¯å¤±è´¥: {e}")
                continue

        if not best_match:
            logger.warning(f"Webhook ä»»åŠ¡: æ‰€æœ‰å€™é€‰æºéƒ½æ— æ³•æä¾›æœ‰æ•ˆåˆ†é›†")
            raise ValueError(f"æ‰€æœ‰å€™é€‰æºéƒ½æ— æ³•æä¾›ç¬¬ {currentEpisodeIndex} é›†")

        # æäº¤å¯¼å…¥ä»»åŠ¡
        await progress_callback(50, f"åœ¨ {best_match.provider} ä¸­æ‰¾åˆ°æœ€ä½³åŒ¹é…é¡¹")

        current_time = get_now().strftime("%H:%M:%S")
        # æ ¹æ®æ¥æºåŠ¨æ€ç”Ÿæˆä»»åŠ¡æ ‡é¢˜å‰ç¼€
        if webhookSource == "media_server":
            source_prefix = "åª’ä½“åº“è¯»å–å¯¼å…¥"
        elif webhookSource in ["emby", "jellyfin", "plex"]:
            source_prefix = f"Webhookè‡ªåŠ¨å¯¼å…¥ ({webhookSource.capitalize()})"
        else:
            source_prefix = f"Webhookè‡ªåŠ¨å¯¼å…¥ ({webhookSource})"

        if mediaType == "tv_series":
            task_title = f"{source_prefix}: {best_match.title} - S{season:02d}E{currentEpisodeIndex:02d} ({best_match.provider}) [{current_time}]"
        else:
            task_title = f"{source_prefix}: {best_match.title} ({best_match.provider}) [{current_time}]"
        unique_key = f"import-{best_match.provider}-{best_match.mediaId}-S{season}-ep{currentEpisodeIndex}"

        # ä¿®æ­£ï¼šä¼˜å…ˆä½¿ç”¨æœç´¢ç»“æœçš„å¹´ä»½ï¼Œå¦‚æœæœç´¢ç»“æœæ²¡æœ‰å¹´ä»½åˆ™ä½¿ç”¨webhookä¼ å…¥çš„å¹´ä»½
        final_year = best_match.year if best_match.year is not None else year
        task_coro = lambda session, cb: generic_import_task(
            provider=best_match.provider, mediaId=best_match.mediaId, year=final_year,
            animeTitle=best_match.title, mediaType=best_match.type,
            season=season, currentEpisodeIndex=currentEpisodeIndex, imageUrl=best_match.imageUrl, config_manager=config_manager, metadata_manager=metadata_manager,
            doubanId=doubanId, tmdbId=tmdbId, imdbId=imdbId, tvdbId=tvdbId, bangumiId=bangumiId, rate_limiter=rate_limiter,
            progress_callback=cb, session=session, manager=manager,
            task_manager=task_manager,
            title_recognition_manager=title_recognition_manager,
            selectedEpisodes=selectedEpisodes,
        )
        await task_manager.submit_task(task_coro, task_title, unique_key=unique_key)

        # æ ¹æ®æ¥æºåŠ¨æ€ç”ŸæˆæˆåŠŸæ¶ˆæ¯
        if webhookSource == "media_server":
            success_message = f"å·²ä¸ºæº '{best_match.provider}' åˆ›å»ºå¯¼å…¥ä»»åŠ¡ã€‚"
        else:
            success_message = f"Webhook: å·²ä¸ºæº '{best_match.provider}' åˆ›å»ºå¯¼å…¥ä»»åŠ¡ã€‚"
        raise TaskSuccess(success_message)
    except TaskSuccess:
        raise
    except Exception as e:
        logger.error(f"Webhook æœç´¢ä¸åˆ†å‘ä»»åŠ¡å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
        raise

