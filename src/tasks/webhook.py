"""Webhookä»»åŠ¡æ¨¡å—"""
import asyncio
import json
import logging
from typing import Callable, Optional, List
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from thefuzz import fuzz
from fastapi import HTTPException

from src.db import crud, models, orm_models, ConfigManager
from src.core import get_now
from src.services import ScraperManager, MetadataSourceManager, TaskManager, TaskSuccess, TitleRecognitionManager
from src.ai import AIMatcherManager
from src.rate_limiter import RateLimiter
from src.utils import (
    parse_search_keyword, ai_type_and_season_mapping_and_correction,
    SearchTimer, SEARCH_TYPE_WEBHOOK
)

# ORM æ¨¡å‹åˆ«å
AnimeSource = orm_models.AnimeSource

logger = logging.getLogger(__name__)


# å»¶è¿Ÿå¯¼å…¥è¾…åŠ©å‡½æ•°
def _get_unified_search():
    from src.services.search import unified_search
    return unified_search

def _get_convert_to_chinese_title():
    from src.services.name_converter import convert_to_chinese_title
    return convert_to_chinese_title


# å»¶è¿Ÿå¯¼å…¥è¾…åŠ©å‡½æ•°
def _get_generic_import_task():
    from .import_core import generic_import_task
    return generic_import_task


async def run_webhook_tasks_directly_manual(
    session: AsyncSession,
    task_ids: List[int],
    task_manager: "TaskManager",
    scraper_manager: "ScraperManager",
    metadata_manager: "MetadataSourceManager",
    config_manager: "ConfigManager",
    ai_matcher_manager: "AIMatcherManager",
    rate_limiter: "RateLimiter",
    title_recognition_manager: "TitleRecognitionManager"
) -> int:
    """ç›´æ¥è·å–å¹¶æ‰§è¡ŒæŒ‡å®šçš„å¾…å¤„ç†Webhookä»»åŠ¡ã€‚"""
    if not task_ids:
        return 0

    stmt = select(orm_models.WebhookTask).where(orm_models.WebhookTask.id.in_(task_ids), orm_models.WebhookTask.status == "pending")
    tasks_to_run = (await session.execute(stmt)).scalars().all()

    submitted_count = 0
    for task in tasks_to_run:
        try:
            payload = json.loads(task.payload)
            # ä½¿ç”¨é»˜è®¤å‚æ•° t=task, p=payload æ•è·å½“å‰å¾ªç¯å˜é‡çš„å€¼,é¿å…é—­åŒ…é—®é¢˜
            task_coro = lambda s, cb, t=task, p=payload: webhook_search_and_dispatch_task(
                webhookSource=t.webhookSource, progress_callback=cb, session=s,
                manager=scraper_manager, task_manager=task_manager,
                metadata_manager=metadata_manager, config_manager=config_manager,
                ai_matcher_manager=ai_matcher_manager,
                rate_limiter=rate_limiter, title_recognition_manager=title_recognition_manager,
                **p
            )
            await task_manager.submit_task(task_coro, task.taskTitle, unique_key=task.uniqueKey)
            await session.delete(task)
            await session.commit()  # ä¸ºæ¯ä¸ªæˆåŠŸæäº¤çš„ä»»åŠ¡å•ç‹¬æäº¤åˆ é™¤æ“ä½œ
            submitted_count += 1
        except HTTPException as e:
            if e.status_code == 409:
                # 409 è¡¨ç¤ºå·²æœ‰ç›¸åŒä»»åŠ¡åœ¨é˜Ÿåˆ—ä¸­ï¼Œè§†ä¸ºæˆåŠŸå¹¶åˆ é™¤å»¶è¿Ÿä»»åŠ¡
                logger.info(f"æ‰‹åŠ¨æ‰§è¡Œ Webhook ä»»åŠ¡ (ID: {task.id}) æ—¶å‘ç°ç›¸åŒä»»åŠ¡å·²åœ¨é˜Ÿåˆ—ä¸­ï¼Œè·³è¿‡ã€‚")
                await session.delete(task)
                await session.commit()
                submitted_count += 1
            else:
                logger.error(f"æ‰‹åŠ¨æ‰§è¡Œ Webhook ä»»åŠ¡ (ID: {task.id}) æ—¶å¤±è´¥: {e}", exc_info=True)
                await session.rollback()
        except Exception as e:
            logger.error(f"æ‰‹åŠ¨æ‰§è¡Œ Webhook ä»»åŠ¡ (ID: {task.id}) æ—¶å¤±è´¥: {e}", exc_info=True)
            await session.rollback()
    return submitted_count


async def webhook_search_and_dispatch_task(
    animeTitle: str,
    mediaType: str,
    season: int,
    currentEpisodeIndex: int,
    searchKeyword: str,
    doubanId: Optional[str],
    tmdbId: Optional[str],
    imdbId: Optional[str],
    tvdbId: Optional[str],
    bangumiId: Optional[str],
    webhookSource: str,
    year: Optional[int],
    progress_callback: Callable,
    session: AsyncSession,
    manager: ScraperManager,
    task_manager: TaskManager, # type: ignore
    metadata_manager: MetadataSourceManager,
    config_manager: ConfigManager,
    ai_matcher_manager: AIMatcherManager,
    rate_limiter: RateLimiter,
    title_recognition_manager: TitleRecognitionManager,
    # åª’ä½“åº“æ•´å­£å¯¼å…¥æ—¶, å¯é€‰: æŒ‡å®šå·²åœ¨åª’ä½“åº“ä¸­é€‰ä¸­çš„åˆ†é›†ç´¢å¼•åˆ—è¡¨
    selectedEpisodes: Optional[List[int]] = None,
):
    """
    Webhook è§¦å‘çš„åå°ä»»åŠ¡ï¼šæœç´¢æ‰€æœ‰æºï¼Œæ‰¾åˆ°æœ€ä½³åŒ¹é…ï¼Œå¹¶ä¸ºè¯¥åŒ¹é…åˆ†å‘ä¸€ä¸ªæ–°çš„ã€å…·ä½“çš„å¯¼å…¥ä»»åŠ¡ã€‚
    """
    generic_import_task = _get_generic_import_task()

    # ğŸš€ V2.1.6: åˆ›å»ºæœç´¢è®¡æ—¶å™¨
    timer = SearchTimer(SEARCH_TYPE_WEBHOOK, f"{animeTitle} S{season:02d}E{currentEpisodeIndex:02d}", logger)
    timer.start()

    # ğŸ”’ Webhook æœç´¢é”ï¼šé˜²æ­¢åŒä¸€ä½œå“åŒå­£çš„å¤šä¸ªè¯·æ±‚åŒæ—¶æœç´¢å¯¼è‡´é‡å¤ä»»åŠ¡
    webhook_lock_key = f"webhook-{animeTitle}-S{season}"
    lock_acquired = await manager.acquire_webhook_search_lock(webhook_lock_key)
    if not lock_acquired:
        # å·²æœ‰ç›¸åŒä½œå“çš„æœç´¢ä»»åŠ¡åœ¨è¿è¡Œï¼Œç›´æ¥è¿”å›æˆåŠŸï¼ˆä»»åŠ¡å·²åœ¨å¤„ç†ä¸­ï¼‰
        logger.info(f"Webhook ä»»åŠ¡: '{animeTitle}' S{season:02d} å·²æœ‰æœç´¢ä»»åŠ¡åœ¨è¿è¡Œï¼Œè·³è¿‡é‡å¤è¯·æ±‚ã€‚")
        raise TaskSuccess(f"ç›¸åŒä½œå“å·²æœ‰æœç´¢ä»»åŠ¡åœ¨å¤„ç†ä¸­ï¼Œæ— éœ€é‡å¤æäº¤ã€‚")

    try:
        logger.info(f"Webhook ä»»åŠ¡: å¼€å§‹ä¸º '{animeTitle}' (S{season:02d}E{currentEpisodeIndex:02d}) æŸ¥æ‰¾æœ€ä½³æº...")
        await progress_callback(5, "æ­£åœ¨æ£€æŸ¥å·²æ”¶è—çš„æº...")

        timer.step_start("æŸ¥æ‰¾æ”¶è—æº")

        # 1. ä¼˜å…ˆæŸ¥æ‰¾å·²æ”¶è—çš„æº (Favorited Source)
        # ğŸ”§ ä¿®å¤ï¼šå…ˆç”¨ title + seasonï¼ˆä¸å¸¦å¹´ä»½ï¼‰æŸ¥è¯¢æ•°æ®åº“
        # å› ä¸º webhook ä¼ æ¥çš„å¹´ä»½å¯èƒ½æ˜¯å•é›†æ”¾æ˜ å¹´ä»½ï¼Œè€Œä¸æ˜¯ä½œå“é¦–æ’­å¹´ä»½
        # ä¾‹å¦‚ï¼šã€Šå‡¡äººä¿®ä»™ä¼ ã€‹TVç‰ˆé¦–æ’­äº2020å¹´ï¼Œä½†2025å¹´çš„æ–°é›† webhook ä¼šä¼  year=2025
        logger.info(f"Webhook ä»»åŠ¡: æŸ¥æ‰¾å·²å­˜åœ¨çš„anime - æ ‡é¢˜='{animeTitle}', å­£æ•°={season}, webhookå¹´ä»½={year}")

        # å…ˆä¸å¸¦å¹´ä»½æŸ¥è¯¢ï¼Œçœ‹æ•°æ®åº“ä¸­æ˜¯å¦å·²æœ‰è¿™éƒ¨ä½œå“
        existing_anime = await crud.find_anime_by_title_season_year(session, animeTitle, season, None, title_recognition_manager, source=None)

        # å¦‚æœæ‰¾åˆ°äº†å·²æœ‰ä½œå“ï¼Œä½¿ç”¨æ•°æ®åº“ä¸­çš„å¹´ä»½è¿›è¡Œåç»­æœç´¢
        effective_year = year  # é»˜è®¤ä½¿ç”¨ webhook ä¼ æ¥çš„å¹´ä»½
        if existing_anime and existing_anime.get('year'):
            db_year = existing_anime['year']
            if year and db_year != year:
                logger.info(f"Webhook ä»»åŠ¡: æ•°æ®åº“å¹´ä»½({db_year}) ä¸ webhook å¹´ä»½({year}) ä¸ä¸€è‡´ï¼Œä½¿ç”¨æ•°æ®åº“å¹´ä»½è¿›è¡Œæœç´¢")
                effective_year = db_year
            else:
                effective_year = db_year
        if existing_anime:
            anime_id = existing_anime['id']
            favorited_source = await crud.find_favorited_source_for_anime(session, anime_id)
            if favorited_source:
                logger.info(f"Webhook ä»»åŠ¡: æ‰¾åˆ°å·²æ”¶è—çš„æº '{favorited_source['providerName']}'ï¼Œå°†ç›´æ¥ä½¿ç”¨æ­¤æºã€‚")
                await progress_callback(10, f"æ‰¾åˆ°å·²æ”¶è—çš„æº: {favorited_source['providerName']}")

                # æ ¹æ®æ¥æºåŠ¨æ€ç”Ÿæˆä»»åŠ¡æ ‡é¢˜å‰ç¼€
                if webhookSource == "media_server":
                    source_prefix = "åª’ä½“åº“è¯»å–å¯¼å…¥"
                elif webhookSource in ["emby", "jellyfin", "plex"]:
                    source_prefix = f"Webhookè‡ªåŠ¨å¯¼å…¥ ({webhookSource.capitalize()})"
                else:
                    source_prefix = f"Webhookè‡ªåŠ¨å¯¼å…¥ ({webhookSource})"

                task_title = f"{source_prefix}: {favorited_source['animeTitle']} - S{season:02d}E{currentEpisodeIndex:02d} ({favorited_source['providerName']})"
                unique_key = f"import-{favorited_source['providerName']}-{favorited_source['mediaId']}-S{season}-ep{currentEpisodeIndex}"
                task_coro = lambda session, cb: generic_import_task(
                    provider=favorited_source['providerName'], mediaId=favorited_source['mediaId'], animeTitle=favorited_source['animeTitle'], year=year,
                    mediaType=favorited_source['mediaType'], season=season, currentEpisodeIndex=currentEpisodeIndex,
                    imageUrl=favorited_source['imageUrl'], doubanId=doubanId, tmdbId=tmdbId, imdbId=imdbId, tvdbId=tvdbId, config_manager=config_manager, metadata_manager=metadata_manager,
                    bangumiId=bangumiId, rate_limiter=rate_limiter,
                    progress_callback=cb, session=session, manager=manager,
                    task_manager=task_manager,
                    title_recognition_manager=title_recognition_manager,
                    selectedEpisodes=selectedEpisodes,
                )
                try:
                    await task_manager.submit_task(task_coro, task_title, unique_key=unique_key)
                except HTTPException as e:
                    if e.status_code == 409:
                        # 409 è¡¨ç¤ºå·²æœ‰ç›¸åŒä»»åŠ¡åœ¨é˜Ÿåˆ—ä¸­ï¼Œè§†ä¸ºæˆåŠŸ
                        logger.info(f"Webhook ä»»åŠ¡: æ”¶è—æºä»»åŠ¡å·²åœ¨é˜Ÿåˆ—ä¸­ (unique_key={unique_key})ï¼Œè·³è¿‡é‡å¤æäº¤ã€‚")
                        raise TaskSuccess(f"ç›¸åŒä»»åŠ¡å·²åœ¨å¤„ç†ä¸­ï¼Œæ— éœ€é‡å¤æäº¤ã€‚")
                    raise

                timer.step_end(details="æ‰¾åˆ°æ”¶è—æº")
                timer.finish()  # æ‰“å°è®¡æ—¶æŠ¥å‘Š
                # æ ¹æ®æ¥æºåŠ¨æ€ç”ŸæˆæˆåŠŸæ¶ˆæ¯
                if webhookSource == "media_server":
                    success_message = f"å·²ä¸ºæ”¶è—æº '{favorited_source['providerName']}' åˆ›å»ºå¯¼å…¥ä»»åŠ¡ã€‚"
                else:
                    success_message = f"Webhook: å·²ä¸ºæ”¶è—æº '{favorited_source['providerName']}' åˆ›å»ºå¯¼å…¥ä»»åŠ¡ã€‚"
                raise TaskSuccess(success_message)

        timer.step_end(details="æ— æ”¶è—æº")

        # 2. å¦‚æœæ²¡æœ‰æ”¶è—æºï¼Œåˆ™å¹¶å‘æœç´¢æ‰€æœ‰å¯ç”¨çš„æº
        logger.info(f"Webhook ä»»åŠ¡: æœªæ‰¾åˆ°æ”¶è—æºï¼Œå¼€å§‹å¹¶å‘æœç´¢æ‰€æœ‰å¯ç”¨çš„æº...")
        await progress_callback(20, "å¹¶å‘æœç´¢æ‰€æœ‰æº...")

        timer.step_start("å…³é”®è¯è§£æä¸é¢„å¤„ç†")
        parsed_keyword = parse_search_keyword(searchKeyword)
        original_title = parsed_keyword["title"]
        season_to_filter = parsed_keyword.get("season") or season
        episode_to_filter = parsed_keyword.get("episode") or currentEpisodeIndex

        # 2.1 Webhook AIæ˜ å°„é…ç½®æ£€æŸ¥
        webhook_tmdb_enabled = await config_manager.get("webhookEnableTmdbSeasonMapping", "true")
        if webhook_tmdb_enabled.lower() != "true":
            logger.info("â—‹ Webhook ç»Ÿä¸€AIæ˜ å°„: åŠŸèƒ½æœªå¯ç”¨")

        # ğŸš€ åç§°è½¬æ¢åŠŸèƒ½ - æ£€æµ‹éä¸­æ–‡æ ‡é¢˜å¹¶å°è¯•è½¬æ¢ä¸ºä¸­æ–‡ï¼ˆåœ¨é¢„å¤„ç†è§„åˆ™ä¹‹å‰æ‰§è¡Œï¼‰
        # åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿç”¨æˆ·ç”¨äºå…ƒæ•°æ®è°ƒç”¨
        webhook_user = models.User(id=0, username="webhook")
        convert_to_chinese_title = _get_convert_to_chinese_title()
        converted_title, conversion_applied = await convert_to_chinese_title(
            original_title,
            config_manager,
            metadata_manager,
            ai_matcher_manager,
            webhook_user
        )
        # ğŸ”§ ç”¨äºåŒ¹é…å’Œæ’åºçš„æ ‡é¢˜ï¼š
        # - å¦‚æœåç§°è½¬æ¢å¼€å…³å¼€å¯ä¸”è½¬æ¢æˆåŠŸï¼Œä½¿ç”¨è½¬æ¢åçš„æ ‡é¢˜
        # - å¦åˆ™ä½¿ç”¨åŸå§‹æ ‡é¢˜ï¼ˆanimeTitleï¼‰
        if conversion_applied:
            logger.info(f"âœ“ Webhook åç§°è½¬æ¢: '{original_title}' â†’ '{converted_title}'")
            original_title = converted_title  # æ›´æ–° original_title ç”¨äºåç»­æœç´¢
            match_title = converted_title     # ä½¿ç”¨è½¬æ¢åçš„æ ‡é¢˜è¿›è¡ŒåŒ¹é…
        else:
            match_title = animeTitle          # ä½¿ç”¨åŸå§‹æ ‡é¢˜è¿›è¡ŒåŒ¹é…

        # åº”ç”¨ä¸ WebUI ä¸€è‡´çš„æ ‡é¢˜é¢„å¤„ç†è§„åˆ™
        search_title = original_title
        if title_recognition_manager:
            (
                processed_title,
                processed_episode,
                processed_season,
                preprocessing_applied,
            ) = await title_recognition_manager.apply_search_preprocessing(
                original_title, episode_to_filter, season_to_filter
            )
            if preprocessing_applied:
                search_title = processed_title
                logger.info(
                    f"âœ“ Webhookæœç´¢é¢„å¤„ç†: '{original_title}' -> '{search_title}'"
                )
                if processed_episode != episode_to_filter:
                    logger.info(
                        f"âœ“ Webhooké›†æ•°é¢„å¤„ç†: {episode_to_filter} -> {processed_episode}"
                    )
                    episode_to_filter = processed_episode
                if processed_season != season_to_filter:
                    logger.info(
                        f"âœ“ Webhookå­£åº¦é¢„å¤„ç†: {season_to_filter} -> {processed_season}"
                    )
                    season_to_filter = processed_season
            else:
                logger.info(f"â—‹ Webhookæœç´¢é¢„å¤„ç†æœªç”Ÿæ•ˆ: '{original_title}'")
        else:
            logger.info("â—‹ æœªé…ç½®æ ‡é¢˜è¯†åˆ«ç®¡ç†å™¨ï¼Œè·³è¿‡Webhookæœç´¢é¢„å¤„ç†ã€‚")

        # æ„é€  episode_info
        episode_info = (
            {"season": season_to_filter, "episode": episode_to_filter}
            if episode_to_filter is not None
            else {"season": season_to_filter}
        )

        logger.info(f"Webhook ä»»åŠ¡: å·²å°†æœç´¢è¯ '{searchKeyword}' è§£æä¸ºæ ‡é¢˜ '{search_title}' è¿›è¡Œæœç´¢ã€‚")
        timer.step_end()

        timer.step_start("ç»Ÿä¸€æœç´¢")
        # ä½¿ç”¨ç»Ÿä¸€çš„æœç´¢å‡½æ•°ï¼ˆä¸ WebUI æœç´¢ä¿æŒä¸€è‡´ï¼‰
        unified_search = _get_unified_search()
        all_search_results = await unified_search(
            search_term=search_title,
            session=session,
            scraper_manager=manager,
            metadata_manager=metadata_manager,
            use_alias_expansion=True,
            use_alias_filtering=True,
            use_title_filtering=True,
            use_source_priority_sorting=True,
            progress_callback=None,
            episode_info=episode_info,
            alias_similarity_threshold=70,
        )
        # æ”¶é›†å•æºæœç´¢è€—æ—¶ä¿¡æ¯
        from src.utils.search_timer import SubStepTiming
        source_timing_sub_steps = [
            SubStepTiming(name=name, duration_ms=dur, result_count=cnt)
            for name, dur, cnt in manager.last_search_timing
        ]
        timer.step_end(details=f"{len(all_search_results)}ä¸ªç»“æœ", sub_steps=source_timing_sub_steps)

        if not all_search_results:
            timer.finish()  # æ‰“å°è®¡æ—¶æŠ¥å‘Š
            raise ValueError(f"æœªæ‰¾åˆ° '{match_title}' çš„ä»»ä½•å¯ç”¨æºã€‚")

        # ä½¿ç”¨ç»Ÿä¸€çš„AIç±»å‹å’Œå­£åº¦æ˜ å°„ä¿®æ­£å‡½æ•°
        if webhook_tmdb_enabled.lower() == "true":
            try:
                timer.step_start("AIæ˜ å°„ä¿®æ­£")
                # è·å–AIåŒ¹é…å™¨
                ai_matcher = await ai_matcher_manager.get_matcher()
                if ai_matcher:
                    logger.info(f"â—‹ Webhook å¼€å§‹ç»Ÿä¸€AIæ˜ å°„ä¿®æ­£: '{original_title}' ({len(all_search_results)} ä¸ªç»“æœ)")

                    # ä½¿ç”¨æ–°çš„ç»Ÿä¸€å‡½æ•°è¿›è¡Œç±»å‹å’Œå­£åº¦ä¿®æ­£
                    mapping_result = await ai_type_and_season_mapping_and_correction(
                        search_title=original_title,
                        search_results=all_search_results,
                        metadata_manager=metadata_manager,
                        ai_matcher=ai_matcher,
                        logger=logger,
                        similarity_threshold=60.0
                    )

                    # åº”ç”¨ä¿®æ­£ç»“æœ
                    if mapping_result['total_corrections'] > 0:
                        logger.info(f"âœ“ Webhook ç»Ÿä¸€AIæ˜ å°„æˆåŠŸ: æ€»è®¡ä¿®æ­£äº† {mapping_result['total_corrections']} ä¸ªç»“æœ")
                        logger.info(f"  - ç±»å‹ä¿®æ­£: {len(mapping_result['type_corrections'])} ä¸ª")
                        logger.info(f"  - å­£åº¦ä¿®æ­£: {len(mapping_result['season_corrections'])} ä¸ª")

                        # æ›´æ–°æœç´¢ç»“æœï¼ˆå·²ç»ç›´æ¥ä¿®æ”¹äº†all_search_resultsï¼‰
                        all_search_results = mapping_result['corrected_results']
                        timer.step_end(details=f"ä¿®æ­£{mapping_result['total_corrections']}ä¸ª")
                    else:
                        logger.info(f"â—‹ Webhook ç»Ÿä¸€AIæ˜ å°„: æœªæ‰¾åˆ°éœ€è¦ä¿®æ­£çš„ä¿¡æ¯")
                        timer.step_end(details="æ— ä¿®æ­£")
                else:
                    logger.warning("â—‹ Webhook AIæ˜ å°„: AIåŒ¹é…å™¨æœªå¯ç”¨æˆ–åˆå§‹åŒ–å¤±è´¥")
                    timer.step_end(details="åŒ¹é…å™¨æœªå¯ç”¨")

            except Exception as e:
                logger.warning(f"Webhook ç»Ÿä¸€AIæ˜ å°„ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
                timer.step_end(details=f"å¤±è´¥: {e}")
        else:
            logger.info("â—‹ Webhook ç»Ÿä¸€AIæ˜ å°„: åŠŸèƒ½æœªå¯ç”¨")

        # 3. æ ¹æ®æ ‡é¢˜å…³é”®è¯ä¿®æ­£åª’ä½“ç±»å‹ï¼ˆä¸ WebUI ä¸€è‡´ï¼‰
        def is_movie_by_title(title: str) -> bool:
            if not title:
                return False
            # å…³é”®è¯åˆ—è¡¨ï¼Œä¸åŒºåˆ†å¤§å°å†™
            movie_keywords = ["å‰§åœºç‰ˆ", "åŠ‡å ´ç‰ˆ", "movie", "æ˜ ç”»"]
            title_lower = title.lower()
            return any(keyword in title_lower for keyword in movie_keywords)

        for item in all_search_results:
            if item.type == "tv_series" and is_movie_by_title(item.title):
                logger.info(
                    f"Webhook: æ ‡é¢˜ '{item.title}' åŒ…å«ç”µå½±å…³é”®è¯ï¼Œç±»å‹ä» 'tv_series' ä¿®æ­£ä¸º 'movie'ã€‚"
                )
                item.type = "movie"

        # 4. å¦‚æœæœç´¢è¯ä¸­æ˜ç¡®æŒ‡å®šäº†å­£åº¦ï¼Œå¯¹ç»“æœè¿›è¡Œè¿‡æ»¤ï¼ˆä¸ WebUI ä¸€è‡´ï¼‰
        # æ³¨æ„ï¼šç”µå½±ç±»å‹ä¸è¿›è¡Œå­£åº¦è¿‡æ»¤
        if season_to_filter and season_to_filter > 0 and mediaType != "movie":
            original_count = len(all_search_results)
            # å½“æŒ‡å®šå­£åº¦æ—¶ï¼Œæˆ‘ä»¬åªå…³å¿ƒç”µè§†å‰§ç±»å‹
            filtered_by_type = [item for item in all_search_results if item.type == "tv_series"]

            # ç„¶ååœ¨ç”µè§†å‰§ç±»å‹ä¸­ï¼Œæˆ‘ä»¬æŒ‰å­£åº¦å·è¿‡æ»¤
            filtered_by_season = [
                item for item in filtered_by_type if item.season == season_to_filter
            ]

            logger.info(
                f"Webhook: æ ¹æ®æŒ‡å®šçš„å­£åº¦ ({season_to_filter}) è¿›è¡Œè¿‡æ»¤ï¼Œä» {original_count} ä¸ªç»“æœä¸­ä¿ç•™äº† {len(filtered_by_season)} ä¸ªã€‚"
            )
            all_search_results = filtered_by_season

        timer.step_start("ç»“æœæ’åºä¸åŒ¹é…")
        # 5. ä½¿ç”¨åŠ æƒæ€»åˆ†åˆ¶é€‰æ‹©æœ€ä½³åŒ¹é…é¡¹
        ordered_settings = await crud.get_all_scraper_settings(session)
        provider_order = {s['providerName']: s['displayOrder'] for s in ordered_settings}

        # æ·»åŠ è°ƒè¯•æ—¥å¿—
        logger.info(f"Webhook ä»»åŠ¡: æ’åºå‰çš„åª’ä½“ç±»å‹: media_type='{mediaType}', å…± {len(all_search_results)} ä¸ªç»“æœ")
        for i, item in enumerate(all_search_results[:5]):
            logger.info(f"  {i+1}. '{item.title}' (Provider: {item.provider}, Type: {item.type})")

        # ğŸ”§ æŸ¥è¯¢åº“å†…å·²æœ‰æºï¼šæœç´¢ç»“æœä¸­å“ªäº› provider+mediaId å·²å­˜åœ¨äº AnimeSource è¡¨ä¸­
        existing_source_keys = set()
        if all_search_results:
            for result in all_search_results:
                stmt = (
                    select(AnimeSource.id)
                    .where(
                        AnimeSource.providerName == result.provider,
                        AnimeSource.mediaId == result.mediaId
                    )
                    .limit(1)
                )
                result_row = await session.execute(stmt)
                if result_row.scalar_one_or_none() is not None:
                    existing_source_keys.add(f"{result.provider}:{result.mediaId}")
            if existing_source_keys:
                logger.info(f"Webhook ä»»åŠ¡: å‘ç° {len(existing_source_keys)} ä¸ªåº“å†…å·²æœ‰æº: {existing_source_keys}")

        # ğŸ”§ åŠ æƒæ€»åˆ†æ’åºï¼ˆæ›¿ä»£æ—§çš„ tuple å­—å…¸åºæ’åºï¼‰
        # æ‰€æœ‰å› ç´ è´¡çŒ®åˆ°ä¸€ä¸ªæ€»åˆ†ï¼Œé¿å… tuple å­—å…¸åºå¯¼è‡´åé¢çš„å› ç´ æˆä¸ºæ­»ä»£ç 
        # ğŸ”§ ä½¿ç”¨ effective_yearï¼ˆæ•°æ®åº“å¹´ä»½ä¼˜å…ˆï¼‰è¿›è¡Œæ’åº
        # ğŸ”§ ä½¿ç”¨ match_titleï¼ˆåç§°è½¬æ¢åçš„æ ‡é¢˜ï¼‰è¿›è¡ŒåŒ¹é…
        normalized_match = match_title.replace("ï¼š", ":").replace(" ", "").strip()

        def _compute_webhook_score(item):
            """è®¡ç®—å•ä¸ªæœç´¢ç»“æœçš„åŠ æƒæ€»åˆ†"""
            score = 0
            item_title_stripped = item.title.strip()
            match_title_stripped = match_title.strip()

            # 1. å®Œå…¨åŒ¹é…æ ‡é¢˜: +10000
            title_exact = item_title_stripped == match_title_stripped
            if title_exact:
                score += 10000

            # 2. å»æ ‡ç‚¹å®Œå…¨åŒ¹é…: +5000
            normalized_item = item.title.replace("ï¼š", ":").replace(" ", "").strip()
            if normalized_item == normalized_match:
                score += 5000

            # 3. é«˜ç›¸ä¼¼åº¦(>98%)ä¸”æ ‡é¢˜é•¿åº¦å·®å¼‚ä¸å¤§: +2000
            token_sort = fuzz.token_sort_ratio(match_title, item.title)
            len_diff = abs(len(item.title) - len(match_title))
            if token_sort > 98 and len_diff <= 10:
                score += 2000

            # 4. è¾ƒé«˜ç›¸ä¼¼åº¦(>95%)ä¸”æ ‡é¢˜é•¿åº¦å·®å¼‚ä¸å¤§: +1000
            if token_sort > 95 and len_diff <= 20:
                score += 1000

            # 5. é•¿æœŸè¿è½½ä½œå“ä¼˜å…ˆ: +800
            if (title_exact and effective_year is not None and
                    item.year is not None and effective_year - item.year >= 3):
                score += 800

            # 6. å¹´ä»½åŒ¹é…: +200ï¼ˆwebhook å¹´ä»½ç»å¸¸ä¸å‡†ç¡®ï¼Œé™ä½æƒé‡ï¼‰
            if effective_year is not None and item.year is not None and item.year == effective_year:
                score += 200

            # 7. å­£åº¦åŒ¹é…: +100
            if season is not None and mediaType == 'tv_series' and item.season == season:
                score += 100

            # 8. ä¸€èˆ¬ç›¸ä¼¼åº¦ (>=85%æ—¶è®¡å…¥å®é™…åˆ†æ•° 0~100)
            token_set = fuzz.token_set_ratio(match_title, item.title)
            if token_set >= 85:
                score += token_set

            # 9. æ ‡é¢˜é•¿åº¦å·®å¼‚æƒ©ç½š
            score -= len_diff * 2

            # 10. å¹´ä»½ä¸åŒ¹é…æƒ©ç½š: -200ï¼ˆwebhook å¹´ä»½ç»å¸¸ä¸å‡†ç¡®ï¼Œé™ä½æƒé‡ï¼‰
            if effective_year is not None and item.year is not None and item.year != effective_year:
                score -= 200

            # 11. æºä¼˜å…ˆçº§åŠ åˆ† (displayOrder è¶Šå°è¶Šå¥½ï¼Œorder=1 â†’ +940, order=2 â†’ +880, ç›¸é‚»å·®60)
            order = provider_order.get(item.provider, 999)
            score += max(0, 1000 - order * 60)

            # 12. ğŸ†• åº“å†…å·²æœ‰æºåŠ åˆ†: +3000
            source_key = f"{item.provider}:{item.mediaId}"
            if source_key in existing_source_keys:
                score += 3000

            return score

        all_search_results.sort(key=_compute_webhook_score, reverse=True)

        # æ·»åŠ æ’åºåçš„è°ƒè¯•æ—¥å¿—ï¼ˆæ˜¾ç¤ºæ€»åˆ†å’Œåº“å†…å·²æœ‰çŠ¶æ€ï¼‰
        logger.info(f"Webhook ä»»åŠ¡: æ’åºåçš„å‰5ä¸ªç»“æœ (effective_year={effective_year}, match_title='{match_title}'):")
        for i, item in enumerate(all_search_results[:5]):
            item_score = _compute_webhook_score(item)
            title_match = "âœ“" if item.title.strip() == match_title.strip() else "âœ—"
            year_match = "âœ“" if effective_year is not None and item.year is not None and item.year == effective_year else ("âœ—" if effective_year is not None and item.year is not None else "-")
            is_long_running = (
                item.title.strip() == match_title.strip() and
                effective_year is not None and
                item.year is not None and
                effective_year - item.year >= 3
            )
            long_running_mark = "ğŸ“º" if is_long_running else ""
            source_key = f"{item.provider}:{item.mediaId}"
            in_library = "ğŸ“š" if source_key in existing_source_keys else ""
            similarity = fuzz.token_set_ratio(match_title, item.title)
            year_info = f"å¹´ä»½: {item.year}" if item.year else "å¹´ä»½: æœªçŸ¥"
            src_order = provider_order.get(item.provider, 999)
            logger.info(f"  {i+1}. [{item_score}åˆ†] '{item.title}' (Provider: {item.provider}[#{src_order}], Type: {item.type}, {year_info}, å¹´ä»½åŒ¹é…: {year_match}, æ ‡é¢˜åŒ¹é…: {title_match}, ç›¸ä¼¼åº¦: {similarity}%) {long_running_mark}{in_library}")

        # è¯„ä¼°æ‰€æœ‰å€™é€‰é¡¹ (ä¸é™åˆ¶æ•°é‡)
        logger.info(f"Webhook ä»»åŠ¡: å…±æœ‰ {len(all_search_results)} ä¸ªæœç´¢ç»“æœ")

        # ä½¿ç”¨AIMatcherManagerè¿›è¡ŒAIåŒ¹é…
        best_match = None
        ai_selected_index = None

        if await ai_matcher_manager.is_enabled():
            logger.info("Webhook ä»»åŠ¡: AIåŒ¹é…å·²å¯ç”¨")
            try:
                # æ„å»ºæŸ¥è¯¢ä¿¡æ¯ï¼ˆä½¿ç”¨ effective_year è€Œä¸æ˜¯ webhook çš„ yearï¼‰
                # ğŸ”§ ä½¿ç”¨ match_titleï¼ˆåç§°è½¬æ¢åçš„æ ‡é¢˜ï¼‰è¿›è¡Œ AI åŒ¹é…
                query_info = {
                    'title': match_title,
                    'season': season if mediaType == 'tv_series' else None,
                    'episode': currentEpisodeIndex,
                    'year': effective_year,  # ä½¿ç”¨æ•°æ®åº“å¹´ä»½ä¼˜å…ˆ
                    'type': mediaType
                }

                # è·å–ç²¾ç¡®æ ‡è®°ä¿¡æ¯
                favorited_info = {}

                for result in all_search_results:
                    # æŸ¥æ‰¾æ˜¯å¦æœ‰ç›¸åŒproviderå’ŒmediaIdçš„æºè¢«æ ‡è®°
                    stmt = (
                        select(AnimeSource.isFavorited)
                        .where(
                            AnimeSource.providerName == result.provider,
                            AnimeSource.mediaId == result.mediaId
                        )
                        .limit(1)
                    )
                    result_row = await session.execute(stmt)
                    is_favorited = result_row.scalar_one_or_none()
                    if is_favorited:
                        key = f"{result.provider}:{result.mediaId}"
                        favorited_info[key] = True

                # ä½¿ç”¨AIMatcherManagerè¿›è¡ŒåŒ¹é…
                ai_selected_index = await ai_matcher_manager.select_best_match(
                    query_info, all_search_results, favorited_info
                )

                if ai_selected_index is not None:
                    best_match = all_search_results[ai_selected_index]
                    logger.info(f"Webhook ä»»åŠ¡: AIåŒ¹é…æˆåŠŸé€‰æ‹©: {best_match.provider} - {best_match.title}")
                else:
                    # æ£€æŸ¥æ˜¯å¦å¯ç”¨ä¼ ç»ŸåŒ¹é…å…œåº•
                    ai_fallback_enabled = (await config_manager.get("aiFallbackEnabled", "true")).lower() == 'true'
                    if ai_fallback_enabled:
                        logger.info("Webhook ä»»åŠ¡: AIåŒ¹é…æœªæ‰¾åˆ°åˆé€‚ç»“æœï¼Œé™çº§åˆ°ä¼ ç»ŸåŒ¹é…")
                    else:
                        logger.warning("Webhook ä»»åŠ¡: AIåŒ¹é…æœªæ‰¾åˆ°åˆé€‚ç»“æœï¼Œä¸”ä¼ ç»ŸåŒ¹é…å…œåº•å·²ç¦ç”¨")
                        raise ValueError("AIåŒ¹é…å¤±è´¥ä¸”ä¼ ç»ŸåŒ¹é…å…œåº•å·²ç¦ç”¨")

            except Exception as e:
                # æ£€æŸ¥æ˜¯å¦å¯ç”¨ä¼ ç»ŸåŒ¹é…å…œåº•
                ai_fallback_enabled = (await config_manager.get("aiFallbackEnabled", "true")).lower() == 'true'
                if ai_fallback_enabled:
                    logger.error(f"Webhook ä»»åŠ¡: AIåŒ¹é…å¤±è´¥ï¼Œé™çº§åˆ°ä¼ ç»ŸåŒ¹é…: {e}")
                else:
                    logger.error(f"Webhook ä»»åŠ¡: AIåŒ¹é…å¤±è´¥ï¼Œä¸”ä¼ ç»ŸåŒ¹é…å…œåº•å·²ç¦ç”¨: {e}")
                    raise ValueError(f"AIåŒ¹é…å¤±è´¥ä¸”ä¼ ç»ŸåŒ¹é…å…œåº•å·²ç¦ç”¨: {e}")
                ai_selected_index = None

        # å¦‚æœAIé€‰æ‹©æˆåŠŸï¼Œä½¿ç”¨AIé€‰æ‹©çš„ç»“æœ
        if best_match is not None:
            logger.info(f"Webhook ä»»åŠ¡: ä½¿ç”¨AIé€‰æ‹©çš„ç»“æœ: {best_match.provider} - {best_match.title}")
            await progress_callback(50, f"åœ¨ {best_match.provider} ä¸­æ‰¾åˆ°æœ€ä½³åŒ¹é…é¡¹")

            current_time = get_now().strftime("%H:%M:%S")
            # æ ¹æ®æ¥æºåŠ¨æ€ç”Ÿæˆä»»åŠ¡æ ‡é¢˜å‰ç¼€
            if webhookSource == "media_server":
                source_prefix = "åª’ä½“åº“è¯»å–å¯¼å…¥"
            elif webhookSource in ["emby", "jellyfin", "plex"]:
                source_prefix = f"Webhookè‡ªåŠ¨å¯¼å…¥ ({webhookSource.capitalize()})"
            else:
                source_prefix = f"Webhookè‡ªåŠ¨å¯¼å…¥ ({webhookSource})"

            if mediaType == "tv_series":
                task_title = f"{source_prefix}: {best_match.title} - S{season:02d}E{currentEpisodeIndex:02d} ({best_match.provider}) [{current_time}]"
            else:
                task_title = f"{source_prefix}: {best_match.title} ({best_match.provider}) [{current_time}]"
            unique_key = f"import-{best_match.provider}-{best_match.mediaId}-S{season}-ep{currentEpisodeIndex}"

            # ä¿®æ­£ï¼šä¼˜å…ˆä½¿ç”¨æœç´¢ç»“æœçš„å¹´ä»½ï¼Œå¦‚æœæœç´¢ç»“æœæ²¡æœ‰å¹´ä»½åˆ™ä½¿ç”¨webhookä¼ å…¥çš„å¹´ä»½
            final_year = best_match.year if best_match.year is not None else year
            task_coro = lambda session, cb: generic_import_task(
                provider=best_match.provider, mediaId=best_match.mediaId, year=final_year,
                animeTitle=best_match.title, mediaType=best_match.type,
                season=season, currentEpisodeIndex=currentEpisodeIndex, imageUrl=best_match.imageUrl, config_manager=config_manager, metadata_manager=metadata_manager,
                doubanId=doubanId, tmdbId=tmdbId, imdbId=imdbId, tvdbId=tvdbId, bangumiId=bangumiId, rate_limiter=rate_limiter,
                progress_callback=cb, session=session, manager=manager,
                task_manager=task_manager,
                title_recognition_manager=title_recognition_manager,
                selectedEpisodes=selectedEpisodes,
            )
            try:
                await task_manager.submit_task(task_coro, task_title, unique_key=unique_key)
            except HTTPException as e:
                if e.status_code == 409:
                    logger.info(f"Webhook ä»»åŠ¡: AIåŒ¹é…ä»»åŠ¡å·²åœ¨é˜Ÿåˆ—ä¸­ (unique_key={unique_key})ï¼Œè·³è¿‡é‡å¤æäº¤ã€‚")
                    raise TaskSuccess(f"ç›¸åŒä»»åŠ¡å·²åœ¨å¤„ç†ä¸­ï¼Œæ— éœ€é‡å¤æäº¤ã€‚")
                raise

            timer.step_end(details="AIåŒ¹é…æˆåŠŸ")
            timer.finish()  # æ‰“å°è®¡æ—¶æŠ¥å‘Š
            # æ ¹æ®æ¥æºåŠ¨æ€ç”ŸæˆæˆåŠŸæ¶ˆæ¯
            if webhookSource == "media_server":
                success_message = f"å·²ä¸ºæº '{best_match.provider}' åˆ›å»ºå¯¼å…¥ä»»åŠ¡ã€‚"
            else:
                success_message = f"Webhook: å·²ä¸ºæº '{best_match.provider}' åˆ›å»ºå¯¼å…¥ä»»åŠ¡ã€‚"
            raise TaskSuccess(success_message)

        # ä¼ ç»ŸåŒ¹é…: ä¼˜å…ˆæŸ¥æ‰¾ç²¾ç¡®æ ‡è®°æºï¼Œå…¶æ¬¡æŸ¥æ‰¾åº“å†…å·²æœ‰æº (éœ€éªŒè¯ç±»å‹åŒ¹é…å’Œæ ‡é¢˜ç›¸ä¼¼åº¦)
        favorited_match = None
        existing_source_match = None  # ğŸ†• åº“å†…å·²æœ‰ä½†æœªæ ‡è®°ç²¾ç¡®çš„æº
        target_type = "movie" if mediaType == "movie" else "tv_series"

        for result in all_search_results:
            # æŸ¥æ‰¾æ˜¯å¦æœ‰ç›¸åŒproviderå’ŒmediaIdçš„æºå­˜åœ¨äºåº“ä¸­
            stmt = (
                select(AnimeSource.isFavorited)
                .where(
                    AnimeSource.providerName == result.provider,
                    AnimeSource.mediaId == result.mediaId
                )
                .limit(1)
            )
            result_row = await session.execute(stmt)
            is_favorited = result_row.scalar_one_or_none()

            if is_favorited is not None:
                # æºå­˜åœ¨äºåº“ä¸­ï¼ŒéªŒè¯ç±»å‹åŒ¹é…å’Œæ ‡é¢˜ç›¸ä¼¼åº¦
                type_matched = result.type == target_type
                similarity = fuzz.token_set_ratio(match_title, result.title)

                if is_favorited:
                    # ç²¾ç¡®æ ‡è®°æºï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
                    logger.info(f"Webhook ä»»åŠ¡: æ‰¾åˆ°ç²¾ç¡®æ ‡è®°æº: {result.provider} - {result.title} "
                               f"(ç±»å‹: {result.type}, ç±»å‹åŒ¹é…: {'âœ“' if type_matched else 'âœ—'}, ç›¸ä¼¼åº¦: {similarity}%)")
                    if type_matched and similarity >= 70:
                        favorited_match = result
                        logger.info(f"Webhook ä»»åŠ¡: ç²¾ç¡®æ ‡è®°æºéªŒè¯é€šè¿‡ (ç±»å‹åŒ¹é…: âœ“, ç›¸ä¼¼åº¦: {similarity}% >= 70%)")
                        break
                    else:
                        logger.warning(f"Webhook ä»»åŠ¡: ç²¾ç¡®æ ‡è®°æºéªŒè¯å¤±è´¥ (ç±»å‹åŒ¹é…: {'âœ“' if type_matched else 'âœ—'}, "
                                     f"ç›¸ä¼¼åº¦: {similarity}% {'<' if similarity < 70 else '>='} 70%)ï¼Œè·³è¿‡")
                elif existing_source_match is None:
                    # ğŸ†• åº“å†…å·²æœ‰æºï¼ˆæ¬¡ä¼˜å…ˆçº§ï¼Œåªè®°å½•ç¬¬ä¸€ä¸ªé€šè¿‡éªŒè¯çš„ï¼‰
                    logger.info(f"Webhook ä»»åŠ¡: æ‰¾åˆ°åº“å†…å·²æœ‰æº: {result.provider} - {result.title} "
                               f"(ç±»å‹: {result.type}, ç±»å‹åŒ¹é…: {'âœ“' if type_matched else 'âœ—'}, ç›¸ä¼¼åº¦: {similarity}%)")
                    if type_matched and similarity >= 70:
                        existing_source_match = result
                        logger.info(f"Webhook ä»»åŠ¡: åº“å†…å·²æœ‰æºéªŒè¯é€šè¿‡ (ç±»å‹åŒ¹é…: âœ“, ç›¸ä¼¼åº¦: {similarity}% >= 70%)")
                    else:
                        logger.info(f"Webhook ä»»åŠ¡: åº“å†…å·²æœ‰æºéªŒè¯å¤±è´¥ï¼Œç»§ç»­æŸ¥æ‰¾")

        # æ£€æŸ¥æ˜¯å¦å¯ç”¨é¡ºå»¶æœºåˆ¶
        fallback_enabled = (await config_manager.get("webhookFallbackEnabled", "false")).lower() == 'true'

        if favorited_match:
            best_match = favorited_match
            logger.info(f"Webhook ä»»åŠ¡: ä½¿ç”¨ç²¾ç¡®æ ‡è®°æº: {best_match.provider} - {best_match.title}")
        elif existing_source_match:
            # ğŸ†• ä½¿ç”¨åº“å†…å·²æœ‰æºï¼ˆæ¬¡ä¼˜å…ˆçº§ï¼‰
            best_match = existing_source_match
            logger.info(f"Webhook ä»»åŠ¡: ä½¿ç”¨åº“å†…å·²æœ‰æº: {best_match.provider} - {best_match.title}")
        elif not fallback_enabled:
            # é¡ºå»¶æœºåˆ¶å…³é—­ï¼ŒéªŒè¯ç¬¬ä¸€ä¸ªç»“æœæ˜¯å¦æ»¡è¶³æ¡ä»¶
            if all_search_results:
                first_result = all_search_results[0]
                # ğŸ”§ ä½¿ç”¨ match_titleï¼ˆåç§°è½¬æ¢åçš„æ ‡é¢˜ï¼‰è¿›è¡Œç›¸ä¼¼åº¦è®¡ç®—
                type_matched = first_result.type == target_type
                similarity = fuzz.token_set_ratio(match_title, first_result.title)

                # å¿…é¡»æ»¡è¶³ï¼šç±»å‹åŒ¹é… AND ç›¸ä¼¼åº¦ >= 70%
                if type_matched and similarity >= 70:
                    best_match = first_result
                    logger.info(f"Webhook ä»»åŠ¡: ä¼ ç»ŸåŒ¹é…æˆåŠŸ: {first_result.provider} - {first_result.title} "
                               f"(ç±»å‹åŒ¹é…: âœ“, ç›¸ä¼¼åº¦: {similarity}%)")
                else:
                    best_match = None
                    logger.warning(f"Webhook ä»»åŠ¡: ä¼ ç»ŸåŒ¹é…å¤±è´¥: ç¬¬ä¸€ä¸ªç»“æœä¸æ»¡è¶³æ¡ä»¶ "
                                 f"(ç±»å‹åŒ¹é…: {'âœ“' if type_matched else 'âœ—'}, ç›¸ä¼¼åº¦: {similarity}%, è¦æ±‚: â‰¥70%)")
            else:
                best_match = None
                logger.warning(f"Webhook ä»»åŠ¡: ä¼ ç»ŸåŒ¹é…å¤±è´¥: æ²¡æœ‰æœç´¢ç»“æœ")

        if best_match is not None:
            await progress_callback(50, f"åœ¨ {best_match.provider} ä¸­æ‰¾åˆ°æœ€ä½³åŒ¹é…é¡¹")

            current_time = get_now().strftime("%H:%M:%S")
            # æ ¹æ®æ¥æºåŠ¨æ€ç”Ÿæˆä»»åŠ¡æ ‡é¢˜å‰ç¼€
            if webhookSource == "media_server":
                source_prefix = "åª’ä½“åº“è¯»å–å¯¼å…¥"
            elif webhookSource in ["emby", "jellyfin", "plex"]:
                source_prefix = f"Webhookè‡ªåŠ¨å¯¼å…¥ ({webhookSource.capitalize()})"
            else:
                source_prefix = f"Webhookè‡ªåŠ¨å¯¼å…¥ ({webhookSource})"

            if mediaType == "tv_series":
                task_title = f"{source_prefix}: {best_match.title} - S{season:02d}E{currentEpisodeIndex:02d} ({best_match.provider}) [{current_time}]"
            else:
                task_title = f"{source_prefix}: {best_match.title} ({best_match.provider}) [{current_time}]"
            unique_key = f"import-{best_match.provider}-{best_match.mediaId}-S{season}-ep{currentEpisodeIndex}"

            # ä¿®æ­£ï¼šä¼˜å…ˆä½¿ç”¨æœç´¢ç»“æœçš„å¹´ä»½ï¼Œå¦‚æœæœç´¢ç»“æœæ²¡æœ‰å¹´ä»½åˆ™ä½¿ç”¨webhookä¼ å…¥çš„å¹´ä»½
            final_year = best_match.year if best_match.year is not None else year
            task_coro = lambda session, cb: generic_import_task(
                provider=best_match.provider, mediaId=best_match.mediaId, year=final_year,
                animeTitle=best_match.title, mediaType=best_match.type,
                season=season, currentEpisodeIndex=currentEpisodeIndex, imageUrl=best_match.imageUrl, config_manager=config_manager, metadata_manager=metadata_manager,
                doubanId=doubanId, tmdbId=tmdbId, imdbId=imdbId, tvdbId=tvdbId, bangumiId=bangumiId, rate_limiter=rate_limiter,
                progress_callback=cb, session=session, manager=manager,
                task_manager=task_manager,
                title_recognition_manager=title_recognition_manager,
                selectedEpisodes=selectedEpisodes,
            )
            try:
                await task_manager.submit_task(task_coro, task_title, unique_key=unique_key)
            except HTTPException as e:
                if e.status_code == 409:
                    logger.info(f"Webhook ä»»åŠ¡: ä¼ ç»ŸåŒ¹é…ä»»åŠ¡å·²åœ¨é˜Ÿåˆ—ä¸­ (unique_key={unique_key})ï¼Œè·³è¿‡é‡å¤æäº¤ã€‚")
                    raise TaskSuccess(f"ç›¸åŒä»»åŠ¡å·²åœ¨å¤„ç†ä¸­ï¼Œæ— éœ€é‡å¤æäº¤ã€‚")
                raise

            timer.step_end(details="ä¼ ç»ŸåŒ¹é…æˆåŠŸ")
            timer.finish()  # æ‰“å°è®¡æ—¶æŠ¥å‘Š
            # æ ¹æ®æ¥æºåŠ¨æ€ç”ŸæˆæˆåŠŸæ¶ˆæ¯
            if webhookSource == "media_server":
                success_message = f"å·²ä¸ºæº '{best_match.provider}' åˆ›å»ºå¯¼å…¥ä»»åŠ¡ã€‚"
            else:
                success_message = f"Webhook: å·²ä¸ºæº '{best_match.provider}' åˆ›å»ºå¯¼å…¥ä»»åŠ¡ã€‚"
            raise TaskSuccess(success_message)

        # é¡ºå»¶æœºåˆ¶å¯ç”¨ï¼šä¾æ¬¡éªŒè¯å€™é€‰æº (æŒ‰åˆ†æ•°ä»é«˜åˆ°ä½)
        logger.info(f"ğŸ”„ Webhook é¡ºå»¶æœºåˆ¶: å·²å¯ç”¨ï¼Œå…±æœ‰ {len(all_search_results)} ä¸ªå€™é€‰æºå¾…éªŒè¯")
        for attempt, candidate in enumerate(all_search_results, 1):
            logger.info(f"â†’ [{attempt}/{len(all_search_results)}] æ­£åœ¨éªŒè¯: {candidate.provider} - {candidate.title} (ID: {candidate.mediaId}, ç±»å‹: {candidate.type})")
            try:
                scraper = manager.get_scraper(candidate.provider)
                if not scraper:
                    logger.warning(f"    {attempt}. {candidate.provider} - æ— æ³•è·å–scraperï¼Œè·³è¿‡")
                    continue

                # è·å–åˆ†é›†åˆ—è¡¨è¿›è¡ŒéªŒè¯
                episodes = await scraper.get_episodes(candidate.mediaId, db_media_type=candidate.type)
                if not episodes:
                    logger.warning(f"    {attempt}. {candidate.provider} - æ²¡æœ‰åˆ†é›†åˆ—è¡¨ï¼Œè·³è¿‡")
                    continue

                # å¦‚æœæ˜¯ç”µå½±ï¼ŒåªåŒ¹é…ç”µå½±ç±»å‹çš„å€™é€‰æº
                if mediaType == "movie":
                    if candidate.type != "movie":
                        logger.warning(f"    {attempt}. {candidate.provider} - ç±»å‹ä¸åŒ¹é… (æœç´¢ç”µå½±ï¼Œä½†å€™é€‰æºæ˜¯{candidate.type})ï¼Œè·³è¿‡")
                        continue
                    logger.info(f"    {attempt}. {candidate.provider} - éªŒè¯é€šè¿‡ (ç”µå½±)")
                # å¦‚æœæ˜¯ç”µè§†å‰§ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ç›®æ ‡é›†æ•°
                else:
                    target_episode = None
                    for ep in episodes:
                        if ep.episodeIndex == currentEpisodeIndex:
                            target_episode = ep
                            break

                    if not target_episode:
                        logger.warning(f"    {attempt}. {candidate.provider} - æ²¡æœ‰ç¬¬ {currentEpisodeIndex} é›†ï¼Œè·³è¿‡")
                        continue

                    logger.info(f"    {attempt}. {candidate.provider} - éªŒè¯é€šè¿‡")

                best_match = candidate
                break
            except Exception as e:
                logger.warning(f"    {attempt}. {candidate.provider} - éªŒè¯å¤±è´¥: {e}")
                continue

        if not best_match:
            logger.warning(f"Webhook ä»»åŠ¡: æ‰€æœ‰å€™é€‰æºéƒ½æ— æ³•æä¾›æœ‰æ•ˆåˆ†é›†")
            raise ValueError(f"æ‰€æœ‰å€™é€‰æºéƒ½æ— æ³•æä¾›ç¬¬ {currentEpisodeIndex} é›†")

        # æäº¤å¯¼å…¥ä»»åŠ¡
        await progress_callback(50, f"åœ¨ {best_match.provider} ä¸­æ‰¾åˆ°æœ€ä½³åŒ¹é…é¡¹")

        current_time = get_now().strftime("%H:%M:%S")
        # æ ¹æ®æ¥æºåŠ¨æ€ç”Ÿæˆä»»åŠ¡æ ‡é¢˜å‰ç¼€
        if webhookSource == "media_server":
            source_prefix = "åª’ä½“åº“è¯»å–å¯¼å…¥"
        elif webhookSource in ["emby", "jellyfin", "plex"]:
            source_prefix = f"Webhookè‡ªåŠ¨å¯¼å…¥ ({webhookSource.capitalize()})"
        else:
            source_prefix = f"Webhookè‡ªåŠ¨å¯¼å…¥ ({webhookSource})"

        if mediaType == "tv_series":
            task_title = f"{source_prefix}: {best_match.title} - S{season:02d}E{currentEpisodeIndex:02d} ({best_match.provider}) [{current_time}]"
        else:
            task_title = f"{source_prefix}: {best_match.title} ({best_match.provider}) [{current_time}]"
        unique_key = f"import-{best_match.provider}-{best_match.mediaId}-S{season}-ep{currentEpisodeIndex}"

        # ä¿®æ­£ï¼šä¼˜å…ˆä½¿ç”¨æœç´¢ç»“æœçš„å¹´ä»½ï¼Œå¦‚æœæœç´¢ç»“æœæ²¡æœ‰å¹´ä»½åˆ™ä½¿ç”¨webhookä¼ å…¥çš„å¹´ä»½
        final_year = best_match.year if best_match.year is not None else year
        task_coro = lambda session, cb: generic_import_task(
            provider=best_match.provider, mediaId=best_match.mediaId, year=final_year,
            animeTitle=best_match.title, mediaType=best_match.type,
            season=season, currentEpisodeIndex=currentEpisodeIndex, imageUrl=best_match.imageUrl, config_manager=config_manager, metadata_manager=metadata_manager,
            doubanId=doubanId, tmdbId=tmdbId, imdbId=imdbId, tvdbId=tvdbId, bangumiId=bangumiId, rate_limiter=rate_limiter,
            progress_callback=cb, session=session, manager=manager,
            task_manager=task_manager,
            title_recognition_manager=title_recognition_manager,
            selectedEpisodes=selectedEpisodes,
        )
        try:
            await task_manager.submit_task(task_coro, task_title, unique_key=unique_key)
        except HTTPException as e:
            if e.status_code == 409:
                logger.info(f"Webhook ä»»åŠ¡: é¡ºå»¶åŒ¹é…ä»»åŠ¡å·²åœ¨é˜Ÿåˆ—ä¸­ (unique_key={unique_key})ï¼Œè·³è¿‡é‡å¤æäº¤ã€‚")
                raise TaskSuccess(f"ç›¸åŒä»»åŠ¡å·²åœ¨å¤„ç†ä¸­ï¼Œæ— éœ€é‡å¤æäº¤ã€‚")
            raise

        timer.step_end(details="é¡ºå»¶åŒ¹é…æˆåŠŸ")
        timer.finish()  # æ‰“å°è®¡æ—¶æŠ¥å‘Š
        # æ ¹æ®æ¥æºåŠ¨æ€ç”ŸæˆæˆåŠŸæ¶ˆæ¯
        if webhookSource == "media_server":
            success_message = f"å·²ä¸ºæº '{best_match.provider}' åˆ›å»ºå¯¼å…¥ä»»åŠ¡ã€‚"
        else:
            success_message = f"Webhook: å·²ä¸ºæº '{best_match.provider}' åˆ›å»ºå¯¼å…¥ä»»åŠ¡ã€‚"
        raise TaskSuccess(success_message)
    except TaskSuccess:
        raise
    except Exception as e:
        timer.finish()  # æ‰“å°è®¡æ—¶æŠ¥å‘Šï¼ˆå³ä½¿å¤±è´¥ä¹Ÿæ‰“å°ï¼‰
        logger.error(f"Webhook æœç´¢ä¸åˆ†å‘ä»»åŠ¡å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
        raise
    finally:
        # ğŸ”“ é‡Šæ”¾ Webhook æœç´¢é”
        await manager.release_webhook_search_lock(webhook_lock_key)

