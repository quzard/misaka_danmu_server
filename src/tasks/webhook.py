"""Webhookä»»åŠ¡æ¨¡å—"""
import asyncio
import json
import logging
from typing import Callable, Optional, List
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from thefuzz import fuzz
from fastapi import HTTPException

from src.db import crud, models, orm_models, ConfigManager
from src.core import get_now
from src.services import ScraperManager, MetadataSourceManager, TaskManager, TaskSuccess, TitleRecognitionManager
from src.rate_limiter import RateLimiter
from src.utils import (
    unified_search, parse_search_keyword, ai_type_and_season_mapping_and_correction,
    SearchTimer, SEARCH_TYPE_WEBHOOK, convert_to_chinese_title
)

# ORM æ¨¡å‹åˆ«å
AnimeSource = orm_models.AnimeSource

logger = logging.getLogger(__name__)


# å»¶è¿Ÿå¯¼å…¥è¾…åŠ©å‡½æ•°
def _get_generic_import_task():
    from .import_core import generic_import_task
    return generic_import_task


async def run_webhook_tasks_directly_manual(
    session: AsyncSession,
    task_ids: List[int],
    task_manager: "TaskManager",
    scraper_manager: "ScraperManager",
    metadata_manager: "MetadataSourceManager",
    config_manager: "ConfigManager",
    ai_matcher_manager: "AIMatcherManager",
    rate_limiter: "RateLimiter",
    title_recognition_manager: "TitleRecognitionManager"
) -> int:
    """ç›´æ¥è·å–å¹¶æ‰§è¡ŒæŒ‡å®šçš„å¾…å¤„ç†Webhookä»»åŠ¡ã€‚"""
    if not task_ids:
        return 0

    stmt = select(orm_models.WebhookTask).where(orm_models.WebhookTask.id.in_(task_ids), orm_models.WebhookTask.status == "pending")
    tasks_to_run = (await session.execute(stmt)).scalars().all()

    submitted_count = 0
    for task in tasks_to_run:
        try:
            payload = json.loads(task.payload)
            task_coro = lambda s, cb: webhook_search_and_dispatch_task(
                webhookSource=task.webhookSource, progress_callback=cb, session=s,
                manager=scraper_manager, task_manager=task_manager,
                metadata_manager=metadata_manager, config_manager=config_manager,
                ai_matcher_manager=ai_matcher_manager,
                rate_limiter=rate_limiter, title_recognition_manager=title_recognition_manager,
                **payload
            )
            await task_manager.submit_task(task_coro, task.taskTitle, unique_key=task.uniqueKey)
            await session.delete(task)
            await session.commit()  # ä¸ºæ¯ä¸ªæˆåŠŸæäº¤çš„ä»»åŠ¡å•ç‹¬æäº¤åˆ é™¤æ“ä½œ
            submitted_count += 1
        except HTTPException as e:
            if e.status_code == 409:
                # 409 è¡¨ç¤ºå·²æœ‰ç›¸åŒä»»åŠ¡åœ¨é˜Ÿåˆ—ä¸­ï¼Œè§†ä¸ºæˆåŠŸå¹¶åˆ é™¤å»¶è¿Ÿä»»åŠ¡
                logger.info(f"æ‰‹åŠ¨æ‰§è¡Œ Webhook ä»»åŠ¡ (ID: {task.id}) æ—¶å‘ç°ç›¸åŒä»»åŠ¡å·²åœ¨é˜Ÿåˆ—ä¸­ï¼Œè·³è¿‡ã€‚")
                await session.delete(task)
                await session.commit()
                submitted_count += 1
            else:
                logger.error(f"æ‰‹åŠ¨æ‰§è¡Œ Webhook ä»»åŠ¡ (ID: {task.id}) æ—¶å¤±è´¥: {e}", exc_info=True)
                await session.rollback()
        except Exception as e:
            logger.error(f"æ‰‹åŠ¨æ‰§è¡Œ Webhook ä»»åŠ¡ (ID: {task.id}) æ—¶å¤±è´¥: {e}", exc_info=True)
            await session.rollback()
    return submitted_count


async def webhook_search_and_dispatch_task(
    animeTitle: str,
    mediaType: str,
    season: int,
    currentEpisodeIndex: int,
    searchKeyword: str,
    doubanId: Optional[str],
    tmdbId: Optional[str],
    imdbId: Optional[str],
    tvdbId: Optional[str],
    bangumiId: Optional[str],
    webhookSource: str,
    year: Optional[int],
    progress_callback: Callable,
    session: AsyncSession,
    manager: ScraperManager,
    task_manager: TaskManager, # type: ignore
    metadata_manager: MetadataSourceManager,
    config_manager: ConfigManager,
    ai_matcher_manager: AIMatcherManager,
    rate_limiter: RateLimiter,
    title_recognition_manager: TitleRecognitionManager,
    # åª’ä½“åº“æ•´å­£å¯¼å…¥æ—¶, å¯é€‰: æŒ‡å®šå·²åœ¨åª’ä½“åº“ä¸­é€‰ä¸­çš„åˆ†é›†ç´¢å¼•åˆ—è¡¨
    selectedEpisodes: Optional[List[int]] = None,
):
    """
    Webhook è§¦å‘çš„åå°ä»»åŠ¡ï¼šæœç´¢æ‰€æœ‰æºï¼Œæ‰¾åˆ°æœ€ä½³åŒ¹é…ï¼Œå¹¶ä¸ºè¯¥åŒ¹é…åˆ†å‘ä¸€ä¸ªæ–°çš„ã€å…·ä½“çš„å¯¼å…¥ä»»åŠ¡ã€‚
    """
    generic_import_task = _get_generic_import_task()

    # ğŸš€ V2.1.6: åˆ›å»ºæœç´¢è®¡æ—¶å™¨
    timer = SearchTimer(SEARCH_TYPE_WEBHOOK, f"{animeTitle} S{season:02d}E{currentEpisodeIndex:02d}", logger)
    timer.start()

    # ğŸ”’ Webhook æœç´¢é”ï¼šé˜²æ­¢åŒä¸€ä½œå“åŒå­£çš„å¤šä¸ªè¯·æ±‚åŒæ—¶æœç´¢å¯¼è‡´é‡å¤ä»»åŠ¡
    webhook_lock_key = f"webhook-{animeTitle}-S{season}"
    lock_acquired = await manager.acquire_webhook_search_lock(webhook_lock_key)
    if not lock_acquired:
        # å·²æœ‰ç›¸åŒä½œå“çš„æœç´¢ä»»åŠ¡åœ¨è¿è¡Œï¼Œç›´æ¥è¿”å›æˆåŠŸï¼ˆä»»åŠ¡å·²åœ¨å¤„ç†ä¸­ï¼‰
        logger.info(f"Webhook ä»»åŠ¡: '{animeTitle}' S{season:02d} å·²æœ‰æœç´¢ä»»åŠ¡åœ¨è¿è¡Œï¼Œè·³è¿‡é‡å¤è¯·æ±‚ã€‚")
        raise TaskSuccess(f"ç›¸åŒä½œå“å·²æœ‰æœç´¢ä»»åŠ¡åœ¨å¤„ç†ä¸­ï¼Œæ— éœ€é‡å¤æäº¤ã€‚")

    try:
        logger.info(f"Webhook ä»»åŠ¡: å¼€å§‹ä¸º '{animeTitle}' (S{season:02d}E{currentEpisodeIndex:02d}) æŸ¥æ‰¾æœ€ä½³æº...")
        await progress_callback(5, "æ­£åœ¨æ£€æŸ¥å·²æ”¶è—çš„æº...")

        timer.step_start("æŸ¥æ‰¾æ”¶è—æº")

        # 1. ä¼˜å…ˆæŸ¥æ‰¾å·²æ”¶è—çš„æº (Favorited Source)
        # ğŸ”§ ä¿®å¤ï¼šå…ˆç”¨ title + seasonï¼ˆä¸å¸¦å¹´ä»½ï¼‰æŸ¥è¯¢æ•°æ®åº“
        # å› ä¸º webhook ä¼ æ¥çš„å¹´ä»½å¯èƒ½æ˜¯å•é›†æ”¾æ˜ å¹´ä»½ï¼Œè€Œä¸æ˜¯ä½œå“é¦–æ’­å¹´ä»½
        # ä¾‹å¦‚ï¼šã€Šå‡¡äººä¿®ä»™ä¼ ã€‹TVç‰ˆé¦–æ’­äº2020å¹´ï¼Œä½†2025å¹´çš„æ–°é›† webhook ä¼šä¼  year=2025
        logger.info(f"Webhook ä»»åŠ¡: æŸ¥æ‰¾å·²å­˜åœ¨çš„anime - æ ‡é¢˜='{animeTitle}', å­£æ•°={season}, webhookå¹´ä»½={year}")

        # å…ˆä¸å¸¦å¹´ä»½æŸ¥è¯¢ï¼Œçœ‹æ•°æ®åº“ä¸­æ˜¯å¦å·²æœ‰è¿™éƒ¨ä½œå“
        existing_anime = await crud.find_anime_by_title_season_year(session, animeTitle, season, None, title_recognition_manager, source=None)

        # å¦‚æœæ‰¾åˆ°äº†å·²æœ‰ä½œå“ï¼Œä½¿ç”¨æ•°æ®åº“ä¸­çš„å¹´ä»½è¿›è¡Œåç»­æœç´¢
        effective_year = year  # é»˜è®¤ä½¿ç”¨ webhook ä¼ æ¥çš„å¹´ä»½
        if existing_anime and existing_anime.get('year'):
            db_year = existing_anime['year']
            if year and db_year != year:
                logger.info(f"Webhook ä»»åŠ¡: æ•°æ®åº“å¹´ä»½({db_year}) ä¸ webhook å¹´ä»½({year}) ä¸ä¸€è‡´ï¼Œä½¿ç”¨æ•°æ®åº“å¹´ä»½è¿›è¡Œæœç´¢")
                effective_year = db_year
            else:
                effective_year = db_year
        if existing_anime:
            anime_id = existing_anime['id']
            favorited_source = await crud.find_favorited_source_for_anime(session, anime_id)
            if favorited_source:
                logger.info(f"Webhook ä»»åŠ¡: æ‰¾åˆ°å·²æ”¶è—çš„æº '{favorited_source['providerName']}'ï¼Œå°†ç›´æ¥ä½¿ç”¨æ­¤æºã€‚")
                await progress_callback(10, f"æ‰¾åˆ°å·²æ”¶è—çš„æº: {favorited_source['providerName']}")

                # æ ¹æ®æ¥æºåŠ¨æ€ç”Ÿæˆä»»åŠ¡æ ‡é¢˜å‰ç¼€
                if webhookSource == "media_server":
                    source_prefix = "åª’ä½“åº“è¯»å–å¯¼å…¥"
                elif webhookSource in ["emby", "jellyfin", "plex"]:
                    source_prefix = f"Webhookè‡ªåŠ¨å¯¼å…¥ ({webhookSource.capitalize()})"
                else:
                    source_prefix = f"Webhookè‡ªåŠ¨å¯¼å…¥ ({webhookSource})"

                task_title = f"{source_prefix}: {favorited_source['animeTitle']} - S{season:02d}E{currentEpisodeIndex:02d} ({favorited_source['providerName']})"
                unique_key = f"import-{favorited_source['providerName']}-{favorited_source['mediaId']}-S{season}-ep{currentEpisodeIndex}"
                task_coro = lambda session, cb: generic_import_task(
                    provider=favorited_source['providerName'], mediaId=favorited_source['mediaId'], animeTitle=favorited_source['animeTitle'], year=year,
                    mediaType=favorited_source['mediaType'], season=season, currentEpisodeIndex=currentEpisodeIndex,
                    imageUrl=favorited_source['imageUrl'], doubanId=doubanId, tmdbId=tmdbId, imdbId=imdbId, tvdbId=tvdbId, config_manager=config_manager, metadata_manager=metadata_manager,
                    bangumiId=bangumiId, rate_limiter=rate_limiter,
                    progress_callback=cb, session=session, manager=manager,
                    task_manager=task_manager,
                    title_recognition_manager=title_recognition_manager,
                    selectedEpisodes=selectedEpisodes,
                )
                try:
                    await task_manager.submit_task(task_coro, task_title, unique_key=unique_key)
                except HTTPException as e:
                    if e.status_code == 409:
                        # 409 è¡¨ç¤ºå·²æœ‰ç›¸åŒä»»åŠ¡åœ¨é˜Ÿåˆ—ä¸­ï¼Œè§†ä¸ºæˆåŠŸ
                        logger.info(f"Webhook ä»»åŠ¡: æ”¶è—æºä»»åŠ¡å·²åœ¨é˜Ÿåˆ—ä¸­ (unique_key={unique_key})ï¼Œè·³è¿‡é‡å¤æäº¤ã€‚")
                        raise TaskSuccess(f"ç›¸åŒä»»åŠ¡å·²åœ¨å¤„ç†ä¸­ï¼Œæ— éœ€é‡å¤æäº¤ã€‚")
                    raise

                timer.step_end(details="æ‰¾åˆ°æ”¶è—æº")
                timer.finish()  # æ‰“å°è®¡æ—¶æŠ¥å‘Š
                # æ ¹æ®æ¥æºåŠ¨æ€ç”ŸæˆæˆåŠŸæ¶ˆæ¯
                if webhookSource == "media_server":
                    success_message = f"å·²ä¸ºæ”¶è—æº '{favorited_source['providerName']}' åˆ›å»ºå¯¼å…¥ä»»åŠ¡ã€‚"
                else:
                    success_message = f"Webhook: å·²ä¸ºæ”¶è—æº '{favorited_source['providerName']}' åˆ›å»ºå¯¼å…¥ä»»åŠ¡ã€‚"
                raise TaskSuccess(success_message)

        timer.step_end(details="æ— æ”¶è—æº")

        # 2. å¦‚æœæ²¡æœ‰æ”¶è—æºï¼Œåˆ™å¹¶å‘æœç´¢æ‰€æœ‰å¯ç”¨çš„æº
        logger.info(f"Webhook ä»»åŠ¡: æœªæ‰¾åˆ°æ”¶è—æºï¼Œå¼€å§‹å¹¶å‘æœç´¢æ‰€æœ‰å¯ç”¨çš„æº...")
        await progress_callback(20, "å¹¶å‘æœç´¢æ‰€æœ‰æº...")

        timer.step_start("å…³é”®è¯è§£æä¸é¢„å¤„ç†")
        parsed_keyword = parse_search_keyword(searchKeyword)
        original_title = parsed_keyword["title"]
        season_to_filter = parsed_keyword.get("season") or season
        episode_to_filter = parsed_keyword.get("episode") or currentEpisodeIndex

        # 2.1 Webhook AIæ˜ å°„é…ç½®æ£€æŸ¥
        webhook_tmdb_enabled = await config_manager.get("webhookEnableTmdbSeasonMapping", "true")
        if webhook_tmdb_enabled.lower() != "true":
            logger.info("â—‹ Webhook ç»Ÿä¸€AIæ˜ å°„: åŠŸèƒ½æœªå¯ç”¨")

        # ğŸš€ åç§°è½¬æ¢åŠŸèƒ½ - æ£€æµ‹éä¸­æ–‡æ ‡é¢˜å¹¶å°è¯•è½¬æ¢ä¸ºä¸­æ–‡ï¼ˆåœ¨é¢„å¤„ç†è§„åˆ™ä¹‹å‰æ‰§è¡Œï¼‰
        # åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿç”¨æˆ·ç”¨äºå…ƒæ•°æ®è°ƒç”¨
        webhook_user = models.User(id=0, username="webhook")
        converted_title, conversion_applied = await convert_to_chinese_title(
            original_title,
            config_manager,
            metadata_manager,
            ai_matcher_manager,
            webhook_user
        )
        # ğŸ”§ ç”¨äºåŒ¹é…å’Œæ’åºçš„æ ‡é¢˜ï¼š
        # - å¦‚æœåç§°è½¬æ¢å¼€å…³å¼€å¯ä¸”è½¬æ¢æˆåŠŸï¼Œä½¿ç”¨è½¬æ¢åçš„æ ‡é¢˜
        # - å¦åˆ™ä½¿ç”¨åŸå§‹æ ‡é¢˜ï¼ˆanimeTitleï¼‰
        if conversion_applied:
            logger.info(f"âœ“ Webhook åç§°è½¬æ¢: '{original_title}' â†’ '{converted_title}'")
            original_title = converted_title  # æ›´æ–° original_title ç”¨äºåç»­æœç´¢
            match_title = converted_title     # ä½¿ç”¨è½¬æ¢åçš„æ ‡é¢˜è¿›è¡ŒåŒ¹é…
        else:
            match_title = animeTitle          # ä½¿ç”¨åŸå§‹æ ‡é¢˜è¿›è¡ŒåŒ¹é…

        # åº”ç”¨ä¸ WebUI ä¸€è‡´çš„æ ‡é¢˜é¢„å¤„ç†è§„åˆ™
        search_title = original_title
        if title_recognition_manager:
            (
                processed_title,
                processed_episode,
                processed_season,
                preprocessing_applied,
            ) = await title_recognition_manager.apply_search_preprocessing(
                original_title, episode_to_filter, season_to_filter
            )
            if preprocessing_applied:
                search_title = processed_title
                logger.info(
                    f"âœ“ Webhookæœç´¢é¢„å¤„ç†: '{original_title}' -> '{search_title}'"
                )
                if processed_episode != episode_to_filter:
                    logger.info(
                        f"âœ“ Webhooké›†æ•°é¢„å¤„ç†: {episode_to_filter} -> {processed_episode}"
                    )
                    episode_to_filter = processed_episode
                if processed_season != season_to_filter:
                    logger.info(
                        f"âœ“ Webhookå­£åº¦é¢„å¤„ç†: {season_to_filter} -> {processed_season}"
                    )
                    season_to_filter = processed_season
            else:
                logger.info(f"â—‹ Webhookæœç´¢é¢„å¤„ç†æœªç”Ÿæ•ˆ: '{original_title}'")
        else:
            logger.info("â—‹ æœªé…ç½®æ ‡é¢˜è¯†åˆ«ç®¡ç†å™¨ï¼Œè·³è¿‡Webhookæœç´¢é¢„å¤„ç†ã€‚")

        # æ„é€  episode_info
        episode_info = (
            {"season": season_to_filter, "episode": episode_to_filter}
            if episode_to_filter is not None
            else {"season": season_to_filter}
        )

        logger.info(f"Webhook ä»»åŠ¡: å·²å°†æœç´¢è¯ '{searchKeyword}' è§£æä¸ºæ ‡é¢˜ '{search_title}' è¿›è¡Œæœç´¢ã€‚")
        timer.step_end()

        timer.step_start("ç»Ÿä¸€æœç´¢")
        # ä½¿ç”¨ç»Ÿä¸€çš„æœç´¢å‡½æ•°ï¼ˆä¸ WebUI æœç´¢ä¿æŒä¸€è‡´ï¼‰
        all_search_results = await unified_search(
            search_term=search_title,
            session=session,
            scraper_manager=manager,
            metadata_manager=metadata_manager,
            use_alias_expansion=True,
            use_alias_filtering=True,
            use_title_filtering=True,
            use_source_priority_sorting=True,
            progress_callback=None,
            episode_info=episode_info,
            alias_similarity_threshold=70,
        )
        # æ”¶é›†å•æºæœç´¢è€—æ—¶ä¿¡æ¯
        from ..search_timer import SubStepTiming
        source_timing_sub_steps = [
            SubStepTiming(name=name, duration_ms=dur, result_count=cnt)
            for name, dur, cnt in manager.last_search_timing
        ]
        timer.step_end(details=f"{len(all_search_results)}ä¸ªç»“æœ", sub_steps=source_timing_sub_steps)

        if not all_search_results:
            timer.finish()  # æ‰“å°è®¡æ—¶æŠ¥å‘Š
            raise ValueError(f"æœªæ‰¾åˆ° '{match_title}' çš„ä»»ä½•å¯ç”¨æºã€‚")

        # ä½¿ç”¨ç»Ÿä¸€çš„AIç±»å‹å’Œå­£åº¦æ˜ å°„ä¿®æ­£å‡½æ•°
        if webhook_tmdb_enabled.lower() == "true":
            try:
                timer.step_start("AIæ˜ å°„ä¿®æ­£")
                # è·å–AIåŒ¹é…å™¨
                ai_matcher = await ai_matcher_manager.get_matcher()
                if ai_matcher:
                    logger.info(f"â—‹ Webhook å¼€å§‹ç»Ÿä¸€AIæ˜ å°„ä¿®æ­£: '{original_title}' ({len(all_search_results)} ä¸ªç»“æœ)")

                    # ä½¿ç”¨æ–°çš„ç»Ÿä¸€å‡½æ•°è¿›è¡Œç±»å‹å’Œå­£åº¦ä¿®æ­£
                    mapping_result = await ai_type_and_season_mapping_and_correction(
                        search_title=original_title,
                        search_results=all_search_results,
                        metadata_manager=metadata_manager,
                        ai_matcher=ai_matcher,
                        logger=logger,
                        similarity_threshold=60.0
                    )

                    # åº”ç”¨ä¿®æ­£ç»“æœ
                    if mapping_result['total_corrections'] > 0:
                        logger.info(f"âœ“ Webhook ç»Ÿä¸€AIæ˜ å°„æˆåŠŸ: æ€»è®¡ä¿®æ­£äº† {mapping_result['total_corrections']} ä¸ªç»“æœ")
                        logger.info(f"  - ç±»å‹ä¿®æ­£: {len(mapping_result['type_corrections'])} ä¸ª")
                        logger.info(f"  - å­£åº¦ä¿®æ­£: {len(mapping_result['season_corrections'])} ä¸ª")

                        # æ›´æ–°æœç´¢ç»“æœï¼ˆå·²ç»ç›´æ¥ä¿®æ”¹äº†all_search_resultsï¼‰
                        all_search_results = mapping_result['corrected_results']
                        timer.step_end(details=f"ä¿®æ­£{mapping_result['total_corrections']}ä¸ª")
                    else:
                        logger.info(f"â—‹ Webhook ç»Ÿä¸€AIæ˜ å°„: æœªæ‰¾åˆ°éœ€è¦ä¿®æ­£çš„ä¿¡æ¯")
                        timer.step_end(details="æ— ä¿®æ­£")
                else:
                    logger.warning("â—‹ Webhook AIæ˜ å°„: AIåŒ¹é…å™¨æœªå¯ç”¨æˆ–åˆå§‹åŒ–å¤±è´¥")
                    timer.step_end(details="åŒ¹é…å™¨æœªå¯ç”¨")

            except Exception as e:
                logger.warning(f"Webhook ç»Ÿä¸€AIæ˜ å°„ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
                timer.step_end(details=f"å¤±è´¥: {e}")
        else:
            logger.info("â—‹ Webhook ç»Ÿä¸€AIæ˜ å°„: åŠŸèƒ½æœªå¯ç”¨")

        # 3. æ ¹æ®æ ‡é¢˜å…³é”®è¯ä¿®æ­£åª’ä½“ç±»å‹ï¼ˆä¸ WebUI ä¸€è‡´ï¼‰
        def is_movie_by_title(title: str) -> bool:
            if not title:
                return False
            # å…³é”®è¯åˆ—è¡¨ï¼Œä¸åŒºåˆ†å¤§å°å†™
            movie_keywords = ["å‰§åœºç‰ˆ", "åŠ‡å ´ç‰ˆ", "movie", "æ˜ ç”»"]
            title_lower = title.lower()
            return any(keyword in title_lower for keyword in movie_keywords)

        for item in all_search_results:
            if item.type == "tv_series" and is_movie_by_title(item.title):
                logger.info(
                    f"Webhook: æ ‡é¢˜ '{item.title}' åŒ…å«ç”µå½±å…³é”®è¯ï¼Œç±»å‹ä» 'tv_series' ä¿®æ­£ä¸º 'movie'ã€‚"
                )
                item.type = "movie"

        # 4. å¦‚æœæœç´¢è¯ä¸­æ˜ç¡®æŒ‡å®šäº†å­£åº¦ï¼Œå¯¹ç»“æœè¿›è¡Œè¿‡æ»¤ï¼ˆä¸ WebUI ä¸€è‡´ï¼‰
        # æ³¨æ„ï¼šç”µå½±ç±»å‹ä¸è¿›è¡Œå­£åº¦è¿‡æ»¤
        if season_to_filter and season_to_filter > 0 and mediaType != "movie":
            original_count = len(all_search_results)
            # å½“æŒ‡å®šå­£åº¦æ—¶ï¼Œæˆ‘ä»¬åªå…³å¿ƒç”µè§†å‰§ç±»å‹
            filtered_by_type = [item for item in all_search_results if item.type == "tv_series"]

            # ç„¶ååœ¨ç”µè§†å‰§ç±»å‹ä¸­ï¼Œæˆ‘ä»¬æŒ‰å­£åº¦å·è¿‡æ»¤
            filtered_by_season = [
                item for item in filtered_by_type if item.season == season_to_filter
            ]

            logger.info(
                f"Webhook: æ ¹æ®æŒ‡å®šçš„å­£åº¦ ({season_to_filter}) è¿›è¡Œè¿‡æ»¤ï¼Œä» {original_count} ä¸ªç»“æœä¸­ä¿ç•™äº† {len(filtered_by_season)} ä¸ªã€‚"
            )
            all_search_results = filtered_by_season

        timer.step_start("ç»“æœæ’åºä¸åŒ¹é…")
        # 5. ä½¿ç”¨ä¸WebUIç›¸åŒçš„æ™ºèƒ½åŒ¹é…ç®—æ³•é€‰æ‹©æœ€ä½³åŒ¹é…é¡¹
        ordered_settings = await crud.get_all_scraper_settings(session)
        provider_order = {s['providerName']: s['displayOrder'] for s in ordered_settings}

        # æ·»åŠ è°ƒè¯•æ—¥å¿—
        logger.info(f"Webhook ä»»åŠ¡: æ’åºå‰çš„åª’ä½“ç±»å‹: media_type='{mediaType}', å…± {len(all_search_results)} ä¸ªç»“æœ")
        for i, item in enumerate(all_search_results[:5]):
            logger.info(f"  {i+1}. '{item.title}' (Provider: {item.provider}, Type: {item.type})")

        # ä½¿ç”¨ä¸WebUIç›¸åŒçš„æ™ºèƒ½æ’åºé€»è¾‘ï¼Œä¼˜åŒ–å¹´ä»½æƒé‡
        # ğŸ”§ ä½¿ç”¨ effective_yearï¼ˆæ•°æ®åº“å¹´ä»½ä¼˜å…ˆï¼‰è¿›è¡Œæ’åºï¼Œè€Œä¸æ˜¯ webhook ä¼ æ¥çš„ year
        # ğŸ”§ ä½¿ç”¨ match_titleï¼ˆåç§°è½¬æ¢åçš„æ ‡é¢˜ï¼‰è¿›è¡ŒåŒ¹é…ï¼Œè€Œä¸æ˜¯åŸå§‹çš„ animeTitle
        all_search_results.sort(
            key=lambda item: (
                # 1. æœ€é«˜ä¼˜å…ˆçº§ï¼šå®Œå…¨åŒ¹é…çš„æ ‡é¢˜
                10000 if item.title.strip() == match_title.strip() else 0,
                # 2. æ¬¡é«˜ä¼˜å…ˆçº§ï¼šå»é™¤æ ‡ç‚¹ç¬¦å·åçš„å®Œå…¨åŒ¹é…
                5000 if item.title.replace("ï¼š", ":").replace(" ", "").strip() == match_title.replace("ï¼š", ":").replace(" ", "").strip() else 0,
                # 3. ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šé«˜ç›¸ä¼¼åº¦åŒ¹é…ï¼ˆ98%ä»¥ä¸Šï¼‰ä¸”æ ‡é¢˜é•¿åº¦å·®å¼‚ä¸å¤§
                2000 if (fuzz.token_sort_ratio(match_title, item.title) > 98 and abs(len(item.title) - len(match_title)) <= 10) else 0,
                # 4. ç¬¬å››ä¼˜å…ˆçº§ï¼šè¾ƒé«˜ç›¸ä¼¼åº¦åŒ¹é…ï¼ˆ95%ä»¥ä¸Šï¼‰ä¸”æ ‡é¢˜é•¿åº¦å·®å¼‚ä¸å¤§
                1000 if (fuzz.token_sort_ratio(match_title, item.title) > 95 and abs(len(item.title) - len(match_title)) <= 20) else 0,
                # 5. ğŸ”§ é•¿æœŸè¿è½½ä½œå“ä¼˜å…ˆï¼šæ ‡é¢˜å®Œå…¨åŒ¹é… + æœç´¢ç»“æœå¹´ä»½æ¯” webhook å¹´ä»½æ—© 3 å¹´ä»¥ä¸Š
                # ç†ç”±ï¼šé•¿æœŸè¿è½½çš„ä½œå“ï¼ˆå¦‚ä»2020å¹´æ’­åˆ°2025å¹´ï¼‰ï¼Œwebhook ä¼ æ¥çš„æ˜¯å•é›†å¹´ä»½ï¼ˆ2025ï¼‰ï¼Œ
                # è€Œæœç´¢ç»“æœä¸­å¹´ä»½æ›´æ—©çš„ç‰ˆæœ¬ï¼ˆ2020ï¼‰æ›´å¯èƒ½æ˜¯ç”¨æˆ·æƒ³è¦çš„åŸç‰ˆ
                800 if (
                    item.title.strip() == match_title.strip() and
                    effective_year is not None and
                    item.year is not None and
                    effective_year - item.year >= 3
                ) else 0,
                # 6. å¹´ä»½åŒ¹é…ï¼ˆä½¿ç”¨ effective_yearï¼Œä¼˜å…ˆä½¿ç”¨æ•°æ®åº“ä¸­çš„é¦–æ’­å¹´ä»½ï¼‰
                500 if effective_year is not None and item.year is not None and item.year == effective_year else 0,
                # 7. å­£åº¦åŒ¹é…ï¼ˆä»…å¯¹ç”µè§†å‰§ï¼‰
                100 if season is not None and mediaType == 'tv_series' and item.season == season else 0,
                # 8. ä¸€èˆ¬ç›¸ä¼¼åº¦ï¼Œä½†å¿…é¡»è¾¾åˆ°85%ä»¥ä¸Šæ‰è€ƒè™‘
                fuzz.token_set_ratio(match_title, item.title) if fuzz.token_set_ratio(match_title, item.title) >= 85 else 0,
                # 9. æƒ©ç½šæ ‡é¢˜é•¿åº¦å·®å¼‚å¤§çš„ç»“æœ
                -abs(len(item.title) - len(match_title)),
                # 10. æƒ©ç½šå¹´ä»½ä¸åŒ¹é…çš„ç»“æœï¼ˆä½¿ç”¨ effective_yearï¼‰
                -500 if effective_year is not None and item.year is not None and item.year != effective_year else 0,
                # 11. æœ€åè€ƒè™‘æºä¼˜å…ˆçº§
                -provider_order.get(item.provider, 999)
            ),
            reverse=True # æŒ‰å¾—åˆ†ä»é«˜åˆ°ä½æ’åº
        )

        # æ·»åŠ æ’åºåçš„è°ƒè¯•æ—¥å¿—
        logger.info(f"Webhook ä»»åŠ¡: æ’åºåçš„å‰5ä¸ªç»“æœ (effective_year={effective_year}, match_title='{match_title}'):")
        for i, item in enumerate(all_search_results[:5]):
            title_match = "âœ“" if item.title.strip() == match_title.strip() else "âœ—"
            year_match = "âœ“" if effective_year is not None and item.year is not None and item.year == effective_year else ("âœ—" if effective_year is not None and item.year is not None else "-")
            # æ£€æŸ¥æ˜¯å¦ä¸ºé•¿æœŸè¿è½½ä½œå“ï¼ˆå¹´ä»½å·®>=3å¹´ï¼‰
            is_long_running = (
                item.title.strip() == match_title.strip() and
                effective_year is not None and
                item.year is not None and
                effective_year - item.year >= 3
            )
            long_running_mark = "ğŸ“º" if is_long_running else ""
            similarity = fuzz.token_set_ratio(match_title, item.title)
            year_info = f"å¹´ä»½: {item.year}" if item.year else "å¹´ä»½: æœªçŸ¥"
            logger.info(f"  {i+1}. '{item.title}' (Provider: {item.provider}, Type: {item.type}, {year_info}, å¹´ä»½åŒ¹é…: {year_match}, æ ‡é¢˜åŒ¹é…: {title_match}, ç›¸ä¼¼åº¦: {similarity}%) {long_running_mark}")

        # è¯„ä¼°æ‰€æœ‰å€™é€‰é¡¹ (ä¸é™åˆ¶æ•°é‡)
        logger.info(f"Webhook ä»»åŠ¡: å…±æœ‰ {len(all_search_results)} ä¸ªæœç´¢ç»“æœ")

        # ä½¿ç”¨AIMatcherManagerè¿›è¡ŒAIåŒ¹é…
        best_match = None
        ai_selected_index = None

        if await ai_matcher_manager.is_enabled():
            logger.info("Webhook ä»»åŠ¡: AIåŒ¹é…å·²å¯ç”¨")
            try:
                # æ„å»ºæŸ¥è¯¢ä¿¡æ¯ï¼ˆä½¿ç”¨ effective_year è€Œä¸æ˜¯ webhook çš„ yearï¼‰
                # ğŸ”§ ä½¿ç”¨ match_titleï¼ˆåç§°è½¬æ¢åçš„æ ‡é¢˜ï¼‰è¿›è¡Œ AI åŒ¹é…
                query_info = {
                    'title': match_title,
                    'season': season if mediaType == 'tv_series' else None,
                    'episode': currentEpisodeIndex,
                    'year': effective_year,  # ä½¿ç”¨æ•°æ®åº“å¹´ä»½ä¼˜å…ˆ
                    'type': mediaType
                }

                # è·å–ç²¾ç¡®æ ‡è®°ä¿¡æ¯
                favorited_info = {}

                for result in all_search_results:
                    # æŸ¥æ‰¾æ˜¯å¦æœ‰ç›¸åŒproviderå’ŒmediaIdçš„æºè¢«æ ‡è®°
                    stmt = (
                        select(AnimeSource.isFavorited)
                        .where(
                            AnimeSource.providerName == result.provider,
                            AnimeSource.mediaId == result.mediaId
                        )
                        .limit(1)
                    )
                    result_row = await session.execute(stmt)
                    is_favorited = result_row.scalar_one_or_none()
                    if is_favorited:
                        key = f"{result.provider}:{result.mediaId}"
                        favorited_info[key] = True

                # ä½¿ç”¨AIMatcherManagerè¿›è¡ŒåŒ¹é…
                ai_selected_index = await ai_matcher_manager.select_best_match(
                    query_info, all_search_results, favorited_info
                )

                if ai_selected_index is not None:
                    best_match = all_search_results[ai_selected_index]
                    logger.info(f"Webhook ä»»åŠ¡: AIåŒ¹é…æˆåŠŸé€‰æ‹©: {best_match.provider} - {best_match.title}")
                else:
                    # æ£€æŸ¥æ˜¯å¦å¯ç”¨ä¼ ç»ŸåŒ¹é…å…œåº•
                    ai_fallback_enabled = (await config_manager.get("aiFallbackEnabled", "true")).lower() == 'true'
                    if ai_fallback_enabled:
                        logger.info("Webhook ä»»åŠ¡: AIåŒ¹é…æœªæ‰¾åˆ°åˆé€‚ç»“æœï¼Œé™çº§åˆ°ä¼ ç»ŸåŒ¹é…")
                    else:
                        logger.warning("Webhook ä»»åŠ¡: AIåŒ¹é…æœªæ‰¾åˆ°åˆé€‚ç»“æœï¼Œä¸”ä¼ ç»ŸåŒ¹é…å…œåº•å·²ç¦ç”¨")
                        raise ValueError("AIåŒ¹é…å¤±è´¥ä¸”ä¼ ç»ŸåŒ¹é…å…œåº•å·²ç¦ç”¨")

            except Exception as e:
                # æ£€æŸ¥æ˜¯å¦å¯ç”¨ä¼ ç»ŸåŒ¹é…å…œåº•
                ai_fallback_enabled = (await config_manager.get("aiFallbackEnabled", "true")).lower() == 'true'
                if ai_fallback_enabled:
                    logger.error(f"Webhook ä»»åŠ¡: AIåŒ¹é…å¤±è´¥ï¼Œé™çº§åˆ°ä¼ ç»ŸåŒ¹é…: {e}")
                else:
                    logger.error(f"Webhook ä»»åŠ¡: AIåŒ¹é…å¤±è´¥ï¼Œä¸”ä¼ ç»ŸåŒ¹é…å…œåº•å·²ç¦ç”¨: {e}")
                    raise ValueError(f"AIåŒ¹é…å¤±è´¥ä¸”ä¼ ç»ŸåŒ¹é…å…œåº•å·²ç¦ç”¨: {e}")
                ai_selected_index = None

        # å¦‚æœAIé€‰æ‹©æˆåŠŸï¼Œä½¿ç”¨AIé€‰æ‹©çš„ç»“æœ
        if best_match is not None:
            logger.info(f"Webhook ä»»åŠ¡: ä½¿ç”¨AIé€‰æ‹©çš„ç»“æœ: {best_match.provider} - {best_match.title}")
            await progress_callback(50, f"åœ¨ {best_match.provider} ä¸­æ‰¾åˆ°æœ€ä½³åŒ¹é…é¡¹")

            current_time = get_now().strftime("%H:%M:%S")
            # æ ¹æ®æ¥æºåŠ¨æ€ç”Ÿæˆä»»åŠ¡æ ‡é¢˜å‰ç¼€
            if webhookSource == "media_server":
                source_prefix = "åª’ä½“åº“è¯»å–å¯¼å…¥"
            elif webhookSource in ["emby", "jellyfin", "plex"]:
                source_prefix = f"Webhookè‡ªåŠ¨å¯¼å…¥ ({webhookSource.capitalize()})"
            else:
                source_prefix = f"Webhookè‡ªåŠ¨å¯¼å…¥ ({webhookSource})"

            if mediaType == "tv_series":
                task_title = f"{source_prefix}: {best_match.title} - S{season:02d}E{currentEpisodeIndex:02d} ({best_match.provider}) [{current_time}]"
            else:
                task_title = f"{source_prefix}: {best_match.title} ({best_match.provider}) [{current_time}]"
            unique_key = f"import-{best_match.provider}-{best_match.mediaId}-S{season}-ep{currentEpisodeIndex}"

            # ä¿®æ­£ï¼šä¼˜å…ˆä½¿ç”¨æœç´¢ç»“æœçš„å¹´ä»½ï¼Œå¦‚æœæœç´¢ç»“æœæ²¡æœ‰å¹´ä»½åˆ™ä½¿ç”¨webhookä¼ å…¥çš„å¹´ä»½
            final_year = best_match.year if best_match.year is not None else year
            task_coro = lambda session, cb: generic_import_task(
                provider=best_match.provider, mediaId=best_match.mediaId, year=final_year,
                animeTitle=best_match.title, mediaType=best_match.type,
                season=season, currentEpisodeIndex=currentEpisodeIndex, imageUrl=best_match.imageUrl, config_manager=config_manager, metadata_manager=metadata_manager,
                doubanId=doubanId, tmdbId=tmdbId, imdbId=imdbId, tvdbId=tvdbId, bangumiId=bangumiId, rate_limiter=rate_limiter,
                progress_callback=cb, session=session, manager=manager,
                task_manager=task_manager,
                title_recognition_manager=title_recognition_manager,
                selectedEpisodes=selectedEpisodes,
            )
            try:
                await task_manager.submit_task(task_coro, task_title, unique_key=unique_key)
            except HTTPException as e:
                if e.status_code == 409:
                    logger.info(f"Webhook ä»»åŠ¡: AIåŒ¹é…ä»»åŠ¡å·²åœ¨é˜Ÿåˆ—ä¸­ (unique_key={unique_key})ï¼Œè·³è¿‡é‡å¤æäº¤ã€‚")
                    raise TaskSuccess(f"ç›¸åŒä»»åŠ¡å·²åœ¨å¤„ç†ä¸­ï¼Œæ— éœ€é‡å¤æäº¤ã€‚")
                raise

            timer.step_end(details="AIåŒ¹é…æˆåŠŸ")
            timer.finish()  # æ‰“å°è®¡æ—¶æŠ¥å‘Š
            # æ ¹æ®æ¥æºåŠ¨æ€ç”ŸæˆæˆåŠŸæ¶ˆæ¯
            if webhookSource == "media_server":
                success_message = f"å·²ä¸ºæº '{best_match.provider}' åˆ›å»ºå¯¼å…¥ä»»åŠ¡ã€‚"
            else:
                success_message = f"Webhook: å·²ä¸ºæº '{best_match.provider}' åˆ›å»ºå¯¼å…¥ä»»åŠ¡ã€‚"
            raise TaskSuccess(success_message)

        # ä¼ ç»ŸåŒ¹é…: ä¼˜å…ˆæŸ¥æ‰¾ç²¾ç¡®æ ‡è®°æº (éœ€éªŒè¯ç±»å‹åŒ¹é…å’Œæ ‡é¢˜ç›¸ä¼¼åº¦)
        favorited_match = None
        target_type = "movie" if mediaType == "movie" else "tv_series"

        for result in all_search_results:
            # æŸ¥æ‰¾æ˜¯å¦æœ‰ç›¸åŒproviderå’ŒmediaIdçš„æºè¢«æ ‡è®°
            stmt = (
                select(AnimeSource.isFavorited)
                .where(
                    AnimeSource.providerName == result.provider,
                    AnimeSource.mediaId == result.mediaId
                )
                .limit(1)
            )
            result_row = await session.execute(stmt)
            is_favorited = result_row.scalar_one_or_none()
            if is_favorited:
                # éªŒè¯ç±»å‹åŒ¹é…å’Œæ ‡é¢˜ç›¸ä¼¼åº¦
                # ğŸ”§ ä½¿ç”¨ match_titleï¼ˆåç§°è½¬æ¢åçš„æ ‡é¢˜ï¼‰è¿›è¡Œç›¸ä¼¼åº¦è®¡ç®—
                type_matched = result.type == target_type
                similarity = fuzz.token_set_ratio(match_title, result.title)
                logger.info(f"Webhook ä»»åŠ¡: æ‰¾åˆ°ç²¾ç¡®æ ‡è®°æº: {result.provider} - {result.title} "
                           f"(ç±»å‹: {result.type}, ç±»å‹åŒ¹é…: {'âœ“' if type_matched else 'âœ—'}, ç›¸ä¼¼åº¦: {similarity}%)")

                # å¿…é¡»æ»¡è¶³ï¼šç±»å‹åŒ¹é… AND ç›¸ä¼¼åº¦ >= 70%
                if type_matched and similarity >= 70:
                    favorited_match = result
                    logger.info(f"Webhook ä»»åŠ¡: ç²¾ç¡®æ ‡è®°æºéªŒè¯é€šè¿‡ (ç±»å‹åŒ¹é…: âœ“, ç›¸ä¼¼åº¦: {similarity}% >= 70%)")
                    break
                else:
                    logger.warning(f"Webhook ä»»åŠ¡: ç²¾ç¡®æ ‡è®°æºéªŒè¯å¤±è´¥ (ç±»å‹åŒ¹é…: {'âœ“' if type_matched else 'âœ—'}, "
                                 f"ç›¸ä¼¼åº¦: {similarity}% {'<' if similarity < 70 else '>='} 70%)ï¼Œè·³è¿‡")

        # æ£€æŸ¥æ˜¯å¦å¯ç”¨é¡ºå»¶æœºåˆ¶
        fallback_enabled = (await config_manager.get("webhookFallbackEnabled", "false")).lower() == 'true'

        if favorited_match:
            best_match = favorited_match
            logger.info(f"Webhook ä»»åŠ¡: ä½¿ç”¨ç²¾ç¡®æ ‡è®°æº: {best_match.provider} - {best_match.title}")
        elif not fallback_enabled:
            # é¡ºå»¶æœºåˆ¶å…³é—­ï¼ŒéªŒè¯ç¬¬ä¸€ä¸ªç»“æœæ˜¯å¦æ»¡è¶³æ¡ä»¶
            if all_search_results:
                first_result = all_search_results[0]
                # ğŸ”§ ä½¿ç”¨ match_titleï¼ˆåç§°è½¬æ¢åçš„æ ‡é¢˜ï¼‰è¿›è¡Œç›¸ä¼¼åº¦è®¡ç®—
                type_matched = first_result.type == target_type
                similarity = fuzz.token_set_ratio(match_title, first_result.title)

                # å¿…é¡»æ»¡è¶³ï¼šç±»å‹åŒ¹é… AND ç›¸ä¼¼åº¦ >= 70%
                if type_matched and similarity >= 70:
                    best_match = first_result
                    logger.info(f"Webhook ä»»åŠ¡: ä¼ ç»ŸåŒ¹é…æˆåŠŸ: {first_result.provider} - {first_result.title} "
                               f"(ç±»å‹åŒ¹é…: âœ“, ç›¸ä¼¼åº¦: {similarity}%)")
                else:
                    best_match = None
                    logger.warning(f"Webhook ä»»åŠ¡: ä¼ ç»ŸåŒ¹é…å¤±è´¥: ç¬¬ä¸€ä¸ªç»“æœä¸æ»¡è¶³æ¡ä»¶ "
                                 f"(ç±»å‹åŒ¹é…: {'âœ“' if type_matched else 'âœ—'}, ç›¸ä¼¼åº¦: {similarity}%, è¦æ±‚: â‰¥70%)")
            else:
                best_match = None
                logger.warning(f"Webhook ä»»åŠ¡: ä¼ ç»ŸåŒ¹é…å¤±è´¥: æ²¡æœ‰æœç´¢ç»“æœ")

        if best_match is not None:
            await progress_callback(50, f"åœ¨ {best_match.provider} ä¸­æ‰¾åˆ°æœ€ä½³åŒ¹é…é¡¹")

            current_time = get_now().strftime("%H:%M:%S")
            # æ ¹æ®æ¥æºåŠ¨æ€ç”Ÿæˆä»»åŠ¡æ ‡é¢˜å‰ç¼€
            if webhookSource == "media_server":
                source_prefix = "åª’ä½“åº“è¯»å–å¯¼å…¥"
            elif webhookSource in ["emby", "jellyfin", "plex"]:
                source_prefix = f"Webhookè‡ªåŠ¨å¯¼å…¥ ({webhookSource.capitalize()})"
            else:
                source_prefix = f"Webhookè‡ªåŠ¨å¯¼å…¥ ({webhookSource})"

            if mediaType == "tv_series":
                task_title = f"{source_prefix}: {best_match.title} - S{season:02d}E{currentEpisodeIndex:02d} ({best_match.provider}) [{current_time}]"
            else:
                task_title = f"{source_prefix}: {best_match.title} ({best_match.provider}) [{current_time}]"
            unique_key = f"import-{best_match.provider}-{best_match.mediaId}-S{season}-ep{currentEpisodeIndex}"

            # ä¿®æ­£ï¼šä¼˜å…ˆä½¿ç”¨æœç´¢ç»“æœçš„å¹´ä»½ï¼Œå¦‚æœæœç´¢ç»“æœæ²¡æœ‰å¹´ä»½åˆ™ä½¿ç”¨webhookä¼ å…¥çš„å¹´ä»½
            final_year = best_match.year if best_match.year is not None else year
            task_coro = lambda session, cb: generic_import_task(
                provider=best_match.provider, mediaId=best_match.mediaId, year=final_year,
                animeTitle=best_match.title, mediaType=best_match.type,
                season=season, currentEpisodeIndex=currentEpisodeIndex, imageUrl=best_match.imageUrl, config_manager=config_manager, metadata_manager=metadata_manager,
                doubanId=doubanId, tmdbId=tmdbId, imdbId=imdbId, tvdbId=tvdbId, bangumiId=bangumiId, rate_limiter=rate_limiter,
                progress_callback=cb, session=session, manager=manager,
                task_manager=task_manager,
                title_recognition_manager=title_recognition_manager,
                selectedEpisodes=selectedEpisodes,
            )
            try:
                await task_manager.submit_task(task_coro, task_title, unique_key=unique_key)
            except HTTPException as e:
                if e.status_code == 409:
                    logger.info(f"Webhook ä»»åŠ¡: ä¼ ç»ŸåŒ¹é…ä»»åŠ¡å·²åœ¨é˜Ÿåˆ—ä¸­ (unique_key={unique_key})ï¼Œè·³è¿‡é‡å¤æäº¤ã€‚")
                    raise TaskSuccess(f"ç›¸åŒä»»åŠ¡å·²åœ¨å¤„ç†ä¸­ï¼Œæ— éœ€é‡å¤æäº¤ã€‚")
                raise

            timer.step_end(details="ä¼ ç»ŸåŒ¹é…æˆåŠŸ")
            timer.finish()  # æ‰“å°è®¡æ—¶æŠ¥å‘Š
            # æ ¹æ®æ¥æºåŠ¨æ€ç”ŸæˆæˆåŠŸæ¶ˆæ¯
            if webhookSource == "media_server":
                success_message = f"å·²ä¸ºæº '{best_match.provider}' åˆ›å»ºå¯¼å…¥ä»»åŠ¡ã€‚"
            else:
                success_message = f"Webhook: å·²ä¸ºæº '{best_match.provider}' åˆ›å»ºå¯¼å…¥ä»»åŠ¡ã€‚"
            raise TaskSuccess(success_message)

        # é¡ºå»¶æœºåˆ¶å¯ç”¨ï¼šä¾æ¬¡éªŒè¯å€™é€‰æº (æŒ‰åˆ†æ•°ä»é«˜åˆ°ä½)
        logger.info(f"ğŸ”„ Webhook é¡ºå»¶æœºåˆ¶: å·²å¯ç”¨ï¼Œå…±æœ‰ {len(all_search_results)} ä¸ªå€™é€‰æºå¾…éªŒè¯")
        for attempt, candidate in enumerate(all_search_results, 1):
            logger.info(f"â†’ [{attempt}/{len(all_search_results)}] æ­£åœ¨éªŒè¯: {candidate.provider} - {candidate.title} (ID: {candidate.mediaId}, ç±»å‹: {candidate.type})")
            try:
                scraper = manager.get_scraper(candidate.provider)
                if not scraper:
                    logger.warning(f"    {attempt}. {candidate.provider} - æ— æ³•è·å–scraperï¼Œè·³è¿‡")
                    continue

                # è·å–åˆ†é›†åˆ—è¡¨è¿›è¡ŒéªŒè¯
                episodes = await scraper.get_episodes(candidate.mediaId, db_media_type=candidate.type)
                if not episodes:
                    logger.warning(f"    {attempt}. {candidate.provider} - æ²¡æœ‰åˆ†é›†åˆ—è¡¨ï¼Œè·³è¿‡")
                    continue

                # å¦‚æœæ˜¯ç”µå½±ï¼ŒåªåŒ¹é…ç”µå½±ç±»å‹çš„å€™é€‰æº
                if mediaType == "movie":
                    if candidate.type != "movie":
                        logger.warning(f"    {attempt}. {candidate.provider} - ç±»å‹ä¸åŒ¹é… (æœç´¢ç”µå½±ï¼Œä½†å€™é€‰æºæ˜¯{candidate.type})ï¼Œè·³è¿‡")
                        continue
                    logger.info(f"    {attempt}. {candidate.provider} - éªŒè¯é€šè¿‡ (ç”µå½±)")
                # å¦‚æœæ˜¯ç”µè§†å‰§ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ç›®æ ‡é›†æ•°
                else:
                    target_episode = None
                    for ep in episodes:
                        if ep.episodeIndex == currentEpisodeIndex:
                            target_episode = ep
                            break

                    if not target_episode:
                        logger.warning(f"    {attempt}. {candidate.provider} - æ²¡æœ‰ç¬¬ {currentEpisodeIndex} é›†ï¼Œè·³è¿‡")
                        continue

                    logger.info(f"    {attempt}. {candidate.provider} - éªŒè¯é€šè¿‡")

                best_match = candidate
                break
            except Exception as e:
                logger.warning(f"    {attempt}. {candidate.provider} - éªŒè¯å¤±è´¥: {e}")
                continue

        if not best_match:
            logger.warning(f"Webhook ä»»åŠ¡: æ‰€æœ‰å€™é€‰æºéƒ½æ— æ³•æä¾›æœ‰æ•ˆåˆ†é›†")
            raise ValueError(f"æ‰€æœ‰å€™é€‰æºéƒ½æ— æ³•æä¾›ç¬¬ {currentEpisodeIndex} é›†")

        # æäº¤å¯¼å…¥ä»»åŠ¡
        await progress_callback(50, f"åœ¨ {best_match.provider} ä¸­æ‰¾åˆ°æœ€ä½³åŒ¹é…é¡¹")

        current_time = get_now().strftime("%H:%M:%S")
        # æ ¹æ®æ¥æºåŠ¨æ€ç”Ÿæˆä»»åŠ¡æ ‡é¢˜å‰ç¼€
        if webhookSource == "media_server":
            source_prefix = "åª’ä½“åº“è¯»å–å¯¼å…¥"
        elif webhookSource in ["emby", "jellyfin", "plex"]:
            source_prefix = f"Webhookè‡ªåŠ¨å¯¼å…¥ ({webhookSource.capitalize()})"
        else:
            source_prefix = f"Webhookè‡ªåŠ¨å¯¼å…¥ ({webhookSource})"

        if mediaType == "tv_series":
            task_title = f"{source_prefix}: {best_match.title} - S{season:02d}E{currentEpisodeIndex:02d} ({best_match.provider}) [{current_time}]"
        else:
            task_title = f"{source_prefix}: {best_match.title} ({best_match.provider}) [{current_time}]"
        unique_key = f"import-{best_match.provider}-{best_match.mediaId}-S{season}-ep{currentEpisodeIndex}"

        # ä¿®æ­£ï¼šä¼˜å…ˆä½¿ç”¨æœç´¢ç»“æœçš„å¹´ä»½ï¼Œå¦‚æœæœç´¢ç»“æœæ²¡æœ‰å¹´ä»½åˆ™ä½¿ç”¨webhookä¼ å…¥çš„å¹´ä»½
        final_year = best_match.year if best_match.year is not None else year
        task_coro = lambda session, cb: generic_import_task(
            provider=best_match.provider, mediaId=best_match.mediaId, year=final_year,
            animeTitle=best_match.title, mediaType=best_match.type,
            season=season, currentEpisodeIndex=currentEpisodeIndex, imageUrl=best_match.imageUrl, config_manager=config_manager, metadata_manager=metadata_manager,
            doubanId=doubanId, tmdbId=tmdbId, imdbId=imdbId, tvdbId=tvdbId, bangumiId=bangumiId, rate_limiter=rate_limiter,
            progress_callback=cb, session=session, manager=manager,
            task_manager=task_manager,
            title_recognition_manager=title_recognition_manager,
            selectedEpisodes=selectedEpisodes,
        )
        try:
            await task_manager.submit_task(task_coro, task_title, unique_key=unique_key)
        except HTTPException as e:
            if e.status_code == 409:
                logger.info(f"Webhook ä»»åŠ¡: é¡ºå»¶åŒ¹é…ä»»åŠ¡å·²åœ¨é˜Ÿåˆ—ä¸­ (unique_key={unique_key})ï¼Œè·³è¿‡é‡å¤æäº¤ã€‚")
                raise TaskSuccess(f"ç›¸åŒä»»åŠ¡å·²åœ¨å¤„ç†ä¸­ï¼Œæ— éœ€é‡å¤æäº¤ã€‚")
            raise

        timer.step_end(details="é¡ºå»¶åŒ¹é…æˆåŠŸ")
        timer.finish()  # æ‰“å°è®¡æ—¶æŠ¥å‘Š
        # æ ¹æ®æ¥æºåŠ¨æ€ç”ŸæˆæˆåŠŸæ¶ˆæ¯
        if webhookSource == "media_server":
            success_message = f"å·²ä¸ºæº '{best_match.provider}' åˆ›å»ºå¯¼å…¥ä»»åŠ¡ã€‚"
        else:
            success_message = f"Webhook: å·²ä¸ºæº '{best_match.provider}' åˆ›å»ºå¯¼å…¥ä»»åŠ¡ã€‚"
        raise TaskSuccess(success_message)
    except TaskSuccess:
        raise
    except Exception as e:
        timer.finish()  # æ‰“å°è®¡æ—¶æŠ¥å‘Šï¼ˆå³ä½¿å¤±è´¥ä¹Ÿæ‰“å°ï¼‰
        logger.error(f"Webhook æœç´¢ä¸åˆ†å‘ä»»åŠ¡å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
        raise
    finally:
        # ğŸ”“ é‡Šæ”¾ Webhook æœç´¢é”
        await manager.release_webhook_search_lock(webhook_lock_key)

