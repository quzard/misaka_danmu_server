"""åˆ†é›†ç®¡ç†ä»»åŠ¡æ¨¡å—"""
import logging
from typing import Callable, List
from sqlalchemy import select, text
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import selectinload

from .. import crud, orm_models
from ..task_manager import TaskSuccess
from ..crud import _get_fs_path_from_web_path

logger = logging.getLogger(__name__)


async def reorder_episodes_task(sourceId: int, session: AsyncSession, progress_callback: Callable):
    """åå°ä»»åŠ¡ï¼šé‡æ–°ç¼–å·ä¸€ä¸ªæºçš„æ‰€æœ‰åˆ†é›†ï¼Œå¹¶åŒæ­¥æ›´æ–°å…¶IDå’Œç‰©ç†æ–‡ä»¶ã€‚"""
    logger.info(f"å¼€å§‹é‡æ•´æº ID: {sourceId} çš„åˆ†é›†é¡ºåºã€‚")
    await progress_callback(0, "æ­£åœ¨è·å–åˆ†é›†åˆ—è¡¨...")

    dialect_name = session.bind.dialect.name
    is_mysql = dialect_name == 'mysql'
    is_postgres = dialect_name == 'postgresql'

    try:
        # æ ¹æ®æ•°æ®åº“æ–¹è¨€ï¼Œæš‚æ—¶ç¦ç”¨å¤–é”®æ£€æŸ¥
        if is_mysql:
            try:
                await session.execute(text("SET FOREIGN_KEY_CHECKS=0;"))
                # MySQLéœ€è¦æäº¤SETå‘½ä»¤
                await session.commit()
            except Exception as e:
                logger.warning(f"æ— æ³•ç¦ç”¨MySQLå¤–é”®æ£€æŸ¥: {e}")
        elif is_postgres:
            # PostgreSQLçš„session_replication_roleå¿…é¡»åœ¨åŒä¸€äº‹åŠ¡ä¸­ä½¿ç”¨
            # ä¸è¦åœ¨è¿™é‡Œæäº¤,ä¿æŒåœ¨åŒä¸€äº‹åŠ¡ä¸­
            try:
                await session.execute(text("SET session_replication_role = 'replica';"))
            except Exception as e:
                logger.error(f"âŒ PostgreSQLæƒé™ä¸è¶³: æ— æ³•è®¾ç½® session_replication_role")
                logger.error(f"ğŸ“ è§£å†³æ–¹æ³•:")
                logger.error(f"   1. æˆäºˆæ•°æ®åº“ç”¨æˆ·è¶…çº§ç”¨æˆ·æƒé™:")
                logger.error(f"      ALTER USER your_username WITH SUPERUSER;")
                logger.error(f"   2. æˆ–è€…ä½¿ç”¨è¶…çº§ç”¨æˆ·è´¦æˆ·è¿æ¥æ•°æ®åº“")
                logger.error(f"   3. æ³¨æ„: è¶…çº§ç”¨æˆ·æƒé™ä»…å»ºè®®åœ¨å¼€å‘/æµ‹è¯•ç¯å¢ƒä½¿ç”¨")
                raise

        try:
            # 1. è·å–è®¡ç®—æ–°IDæ‰€éœ€çš„ä¿¡æ¯
            source_info = await crud.get_anime_source_info(session, sourceId)
            if not source_info:
                raise ValueError(f"æ‰¾ä¸åˆ°æºID {sourceId} çš„ä¿¡æ¯ã€‚")
            anime_id = source_info['animeId']
            source_order = source_info.get('sourceOrder')

            if source_order is None:
                # å¦‚æœç”±äºæŸç§åŸå› ï¼ˆä¾‹å¦‚ï¼Œéå¸¸æ—§çš„æ•°æ®ï¼‰æ²¡æœ‰ sourceOrderï¼Œåˆ™ä¸å…è®¸é‡æ•´
                raise ValueError(f"æº ID {sourceId} æ²¡æœ‰æŒä¹…åŒ–çš„ sourceOrderï¼Œæ— æ³•é‡æ•´ã€‚è¯·å°è¯•é‡æ–°æ·»åŠ æ­¤æºã€‚")

            # 2. è·å–æ‰€æœ‰åˆ†é›†ORMå¯¹è±¡ï¼ŒæŒ‰ç°æœ‰é¡ºåºæ’åº
            episodes_orm_res = await session.execute(
                select(orm_models.Episode)
                .where(orm_models.Episode.sourceId == sourceId)
                .order_by(orm_models.Episode.episodeIndex, orm_models.Episode.id)
            )
            episodes_to_migrate = episodes_orm_res.scalars().all()

            if not episodes_to_migrate:
                raise TaskSuccess("æ²¡æœ‰æ‰¾åˆ°åˆ†é›†ï¼Œæ— éœ€é‡æ•´ã€‚")

            await progress_callback(10, "æ­£åœ¨è®¡ç®—æ–°çš„åˆ†é›†ç¼–å·...")

            old_episodes_to_delete = []
            new_episodes_to_add = []

            for i, old_ep in enumerate(episodes_to_migrate):
                new_index = i + 1
                new_id = int(f"25{anime_id:06d}{source_order:02d}{new_index:04d}")

                if old_ep.id == new_id and old_ep.episodeIndex == new_index:
                    continue

                # ä¿®æ­£ï¼šä½¿ç”¨æ­£ç¡®çš„Webè·¯å¾„æ ¼å¼ï¼Œå¹¶ä½¿ç”¨è¾…åŠ©å‡½æ•°è¿›è¡Œæ–‡ä»¶è·¯å¾„è½¬æ¢
                new_danmaku_web_path = f"/app/config/danmaku/{anime_id}/{new_id}.xml" if old_ep.danmakuFilePath else None
                if old_ep.danmakuFilePath:
                    old_full_path = _get_fs_path_from_web_path(old_ep.danmakuFilePath)
                    new_full_path = _get_fs_path_from_web_path(new_danmaku_web_path)
                    if old_full_path.is_file() and old_full_path != new_full_path:
                        new_full_path.parent.mkdir(parents=True, exist_ok=True)
                        old_full_path.rename(new_full_path)

                new_episodes_to_add.append(orm_models.Episode(id=new_id, sourceId=old_ep.sourceId, episodeIndex=new_index, title=old_ep.title, sourceUrl=old_ep.sourceUrl, providerEpisodeId=old_ep.providerEpisodeId, fetchedAt=old_ep.fetchedAt, commentCount=old_ep.commentCount, danmakuFilePath=new_danmaku_web_path))
                old_episodes_to_delete.append(old_ep)

            if not old_episodes_to_delete:
                raise TaskSuccess("æ‰€æœ‰åˆ†é›†é¡ºåºå’ŒIDéƒ½æ­£ç¡®ï¼Œæ— éœ€é‡æ•´ã€‚")

            await progress_callback(30, f"å‡†å¤‡è¿ç§» {len(old_episodes_to_delete)} ä¸ªåˆ†é›†...")

            for old_ep in old_episodes_to_delete:
                await session.delete(old_ep)
            await session.flush()
            session.add_all(new_episodes_to_add)

            await session.commit()
            raise TaskSuccess(f"é‡æ•´å®Œæˆï¼Œå…±è¿ç§»äº† {len(new_episodes_to_add)} ä¸ªåˆ†é›†çš„è®°å½•ã€‚")
        except TaskSuccess:
            # TaskSuccess ä¸æ˜¯é”™è¯¯ï¼Œç›´æ¥å‘ä¸Šä¼ é€’
            raise
        except Exception as e:
            await session.rollback()
            logger.error(f"é‡æ•´åˆ†é›†ä»»åŠ¡ (æºID: {sourceId}) äº‹åŠ¡ä¸­å¤±è´¥: {e}", exc_info=True)
            raise
        finally:
            # åŠ¡å¿…é‡æ–°å¯ç”¨å¤–é”®æ£€æŸ¥/æ¢å¤ä¼šè¯è§’è‰²
            if is_mysql:
                try:
                    await session.execute(text("SET FOREIGN_KEY_CHECKS=1;"))
                    await session.commit()
                except Exception as e:
                    logger.warning(f"æ— æ³•æ¢å¤MySQLå¤–é”®æ£€æŸ¥: {e}")
            elif is_postgres:
                try:
                    await session.execute(text("SET session_replication_role = 'origin';"))
                    await session.commit()
                except Exception as e:
                    logger.warning(f"æ— æ³•æ¢å¤PostgreSQLä¼šè¯è§’è‰²: {e}")
    except Exception as e:
        logger.error(f"é‡æ•´åˆ†é›†ä»»åŠ¡ (æºID: {sourceId}) å¤±è´¥: {e}", exc_info=True)
        raise


async def offset_episodes_task(episode_ids: List[int], offset: int, session: AsyncSession, progress_callback: Callable):
    """åå°ä»»åŠ¡ï¼šå¯¹é€‰ä¸­çš„åˆ†é›†è¿›è¡Œé›†æ•°åç§»ï¼Œå¹¶åŒæ­¥æ›´æ–°å…¶IDå’Œç‰©ç†æ–‡ä»¶ã€‚"""
    if not episode_ids:
        raise TaskSuccess("æ²¡æœ‰é€‰ä¸­ä»»ä½•åˆ†é›†ã€‚")

    logger.info(f"å¼€å§‹é›†æ•°åç§»ä»»åŠ¡ï¼Œåç§»é‡: {offset}, åˆ†é›†IDs: {episode_ids}")
    await progress_callback(0, "æ­£åœ¨éªŒè¯åç§»æ“ä½œ...")

    dialect_name = session.bind.dialect.name
    is_mysql = dialect_name == 'mysql'
    is_postgres = dialect_name == 'postgresql'

    try:
        # --- Execution Phase ---
        # Temporarily disable foreign key checks
        if is_mysql:
            try:
                await session.execute(text("SET FOREIGN_KEY_CHECKS=0;"))
                # MySQLéœ€è¦æäº¤SETå‘½ä»¤
                await session.commit()
            except Exception as e:
                logger.warning(f"æ— æ³•ç¦ç”¨MySQLå¤–é”®æ£€æŸ¥: {e}")
        elif is_postgres:
            # PostgreSQLçš„session_replication_roleå¿…é¡»åœ¨åŒä¸€äº‹åŠ¡ä¸­ä½¿ç”¨
            # ä¸è¦åœ¨è¿™é‡Œæäº¤,ä¿æŒåœ¨åŒä¸€äº‹åŠ¡ä¸­
            try:
                await session.execute(text("SET session_replication_role = 'replica';"))
            except Exception as e:
                logger.error(f"âŒ PostgreSQLæƒé™ä¸è¶³: æ— æ³•è®¾ç½® session_replication_role")
                logger.error(f"ğŸ“ è§£å†³æ–¹æ³•:")
                logger.error(f"   1. æˆäºˆæ•°æ®åº“ç”¨æˆ·è¶…çº§ç”¨æˆ·æƒé™:")
                logger.error(f"      ALTER USER your_username WITH SUPERUSER;")
                logger.error(f"   2. æˆ–è€…ä½¿ç”¨è¶…çº§ç”¨æˆ·è´¦æˆ·è¿æ¥æ•°æ®åº“")
                logger.error(f"   3. æ³¨æ„: è¶…çº§ç”¨æˆ·æƒé™ä»…å»ºè®®åœ¨å¼€å‘/æµ‹è¯•ç¯å¢ƒä½¿ç”¨")
                raise
        # --- Validation Phase ---
        # 1. Fetch all selected episodes and ensure they belong to the same source
        selected_episodes_res = await session.execute(
            select(orm_models.Episode)
            .where(orm_models.Episode.id.in_(episode_ids))
            .options(selectinload(orm_models.Episode.source))
        )
        selected_episodes = selected_episodes_res.scalars().all()

        if len(selected_episodes) != len(set(episode_ids)):
            raise ValueError("éƒ¨åˆ†é€‰ä¸­çš„åˆ†é›†æœªæ‰¾åˆ°ã€‚")

        first_ep = selected_episodes[0]
        source_id = first_ep.sourceId
        anime_id = first_ep.source.animeId
        source_order = first_ep.source.sourceOrder

        if any(ep.sourceId != source_id for ep in selected_episodes):
            raise ValueError("é€‰ä¸­çš„åˆ†é›†å¿…é¡»å±äºåŒä¸€ä¸ªæ•°æ®æºã€‚")

        if source_order is None:
            raise ValueError(f"æº ID {source_id} æ²¡æœ‰æŒä¹…åŒ–çš„ sourceOrderï¼Œæ— æ³•è¿›è¡Œåç§»æ“ä½œã€‚")

        # 2. Check for conflicts
        selected_indices = {ep.episodeIndex for ep in selected_episodes}
        new_indices = {idx + offset for idx in selected_indices}

        if any(idx <= 0 for idx in new_indices):
            # æ­¤æ£€æŸ¥ä½œä¸ºæœ€åçš„å®‰å…¨é˜²çº¿ï¼ŒAPIå±‚åº”å·²è¿›è¡Œåˆæ­¥éªŒè¯
            raise ValueError("åç§»åçš„é›†æ•°å¿…é¡»å¤§äº0ã€‚")

        all_source_episodes_res = await session.execute(
            select(orm_models.Episode.episodeIndex).where(orm_models.Episode.sourceId == source_id)
        )
        all_existing_indices = set(all_source_episodes_res.scalars().all())
        unselected_indices = all_existing_indices - selected_indices

        conflicts = new_indices.intersection(unselected_indices)
        if conflicts:
            raise ValueError(f"æ“ä½œå°†å¯¼è‡´é›†æ•°å†²çªï¼Œæ— æ³•æ‰§è¡Œã€‚å†²çªé›†æ•°: {sorted(list(conflicts))}")

        await progress_callback(20, "éªŒè¯é€šè¿‡ï¼Œå‡†å¤‡è¿ç§»æ•°æ®...")

        # --- Execution Phase ---
        try:
            old_episodes_to_delete = []
            new_episodes_to_add = []

            total_to_migrate = len(selected_episodes)
            for i, old_ep in enumerate(selected_episodes):
                await progress_callback(20 + int((i / total_to_migrate) * 70), f"æ­£åœ¨å¤„ç†åˆ†é›† {i+1}/{total_to_migrate}...")

                new_index = old_ep.episodeIndex + offset
                new_id = int(f"25{anime_id:06d}{source_order:02d}{new_index:04d}")

                new_danmaku_web_path = None
                if old_ep.danmakuFilePath:
                    new_danmaku_web_path = f"/app/config/danmaku/{anime_id}/{new_id}.xml"
                    old_full_path = _get_fs_path_from_web_path(old_ep.danmakuFilePath)
                    new_full_path = _get_fs_path_from_web_path(new_danmaku_web_path)
                    if old_full_path and old_full_path.is_file() and old_full_path != new_full_path:
                        new_full_path.parent.mkdir(parents=True, exist_ok=True)
                        old_full_path.rename(new_full_path)

                new_episodes_to_add.append(orm_models.Episode(
                    id=new_id,
                    sourceId=old_ep.sourceId,
                    episodeIndex=new_index,
                    title=old_ep.title,
                    sourceUrl=old_ep.sourceUrl,
                    providerEpisodeId=old_ep.providerEpisodeId,
                    fetchedAt=old_ep.fetchedAt,
                    commentCount=old_ep.commentCount,
                    danmakuFilePath=new_danmaku_web_path
                ))
                old_episodes_to_delete.append(old_ep)

            # Perform DB operations
            for old_ep in old_episodes_to_delete:
                await session.delete(old_ep)
            await session.flush()

            session.add_all(new_episodes_to_add)
            await session.commit()

            raise TaskSuccess(f"é›†æ•°åç§»å®Œæˆï¼Œå…±è¿ç§»äº† {len(new_episodes_to_add)} ä¸ªåˆ†é›†ã€‚")

        except TaskSuccess:
            # TaskSuccess ä¸æ˜¯é”™è¯¯ï¼Œç›´æ¥å‘ä¸Šä¼ é€’
            raise
        except Exception as e:
            await session.rollback()
            logger.error(f"é›†æ•°åç§»ä»»åŠ¡ (æºID: {source_id}) äº‹åŠ¡ä¸­å¤±è´¥: {e}", exc_info=True)
            raise
        finally:
            # Re-enable foreign key checks
            if is_mysql:
                try:
                    await session.execute(text("SET FOREIGN_KEY_CHECKS=1;"))
                except Exception as e:
                    logger.warning(f"æ— æ³•æ¢å¤MySQLå¤–é”®æ£€æŸ¥: {e}")
            elif is_postgres:
                try:
                    await session.execute(text("SET session_replication_role = 'origin';"))
                except Exception as e:
                    logger.warning(f"æ— æ³•æ¢å¤PostgreSQLä¼šè¯è§’è‰²: {e}")

    except ValueError as e:
        # Catch validation errors and report them as task failures
        logger.error(f"é›†æ•°åç§»ä»»åŠ¡éªŒè¯å¤±è´¥: {e}")
        raise TaskSuccess(f"æ“ä½œå¤±è´¥: {e}")
    except Exception as e:
        logger.error(f"é›†æ•°åç§»ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        raise

